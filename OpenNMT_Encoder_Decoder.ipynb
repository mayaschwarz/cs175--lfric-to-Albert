{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OpenNMT Encoder Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lWn1nklMSqHm",
        "5rBaibtnSnz0",
        "FPrbGwuRQQJF",
        "jUZIeeDNlJJD"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "11CHwrqLnOYq7kakfXe-XpdM66I-yWdHi",
      "authorship_tag": "ABX9TyNCn/nd50ogZ0hnigAMDzjI"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7QLIgUmO4gf"
      },
      "source": [
        "# OpenNMT-py Encoder Decoder LSTM\r\n",
        "\r\n",
        "Sequence-to-Sequence Encoder-Decoder Models for translating Middle, Modern, and Old English\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRUvKr9nywe"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "# default location for the drive\r\n",
        "ROOT = \"/content/gdrive\"\r\n",
        "\r\n",
        "drive.mount(ROOT)\r\n",
        "\r\n",
        "# Check that can access the shared drive\r\n",
        "!ls \"{ROOT}/Shareddrives/CS 175 Project\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmTJLiqgn1X1",
        "outputId": "4b26230e-e1f3-4ea2-f4f1-d13f684bc9c9"
      },
      "source": [
        "# Clone github repository setup\r\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\r\n",
        "from os.path import join  \r\n",
        "\r\n",
        "# path to your project on Google Drive\r\n",
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/cs175-Aelfric-to-Albert' \r\n",
        "GIT_USERNAME = \"mayaschwarz\" \r\n",
        "\r\n",
        "# Put your Token here! Do not save to the repo with it!\r\n",
        "GIT_TOKEN_PATH = join(ROOT, \"Shareddrives/CS 175 Project/token.txt\")\r\n",
        "GIT_TOKEN = \"\"\r\n",
        "\r\n",
        "with open(GIT_TOKEN_PATH, 'r') as f:\r\n",
        "  GIT_TOKEN = f.readline().strip()\r\n",
        "\r\n",
        "if not GIT_TOKEN:\r\n",
        "  raise ValueError(\"GIT_TOKEN MISSING\")\r\n",
        "\r\n",
        "GIT_REPOSITORY = \"cs175--lfric-to-Albert\" \r\n",
        "\r\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\r\n",
        "\r\n",
        "# It's good to print out the value if you are not sure \r\n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \r\n",
        "\r\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\r\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\r\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  /content/gdrive/My Drive/cs175-Aelfric-to-Albert\n",
            "GIT_PATH:  https://5724b257c777c6dbb9bc086821f822ef220e3126@github.com/mayaschwarz/cs175--lfric-to-Albert.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MsXX3Smn2hs",
        "outputId": "c8bcea56-27b2-4be9-c843-67c5f71be5e8"
      },
      "source": [
        "# Answer input query for downloading git repository\r\n",
        "while True:\r\n",
        "    response = input(\"Are you sure you want to download the repo? Doing so will delete all unpush work. [y|N] \").lower().strip()\r\n",
        "    if not response or response[0] == 'n':\r\n",
        "        break\r\n",
        "    elif response[0] == \"y\":\r\n",
        "        !rm -rv \"{PROJECT_PATH}\"\r\n",
        "        !mkdir -p \"{PROJECT_PATH}\" \r\n",
        "        !git clone \"{GIT_PATH}\" \"{PROJECT_PATH}\"\r\n",
        "        break\r\n",
        "\r\n",
        "# cd into the repository\r\n",
        "%cd \"{PROJECT_PATH}\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are you sure you want to download the repo? Doing so will delete all unpush work. [y|N] N\n",
            "/content/gdrive/My Drive/cs175-Aelfric-to-Albert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpBwKtztn31i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0051839d-0e4b-4d48-fd08-ffbfe1ed624a"
      },
      "source": [
        "# Check that repository is up to date\r\n",
        "!git pull "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leBL9jCcJ6cK",
        "outputId": "a046ca0c-f16f-41d5-fa8e-179c9efaf93c"
      },
      "source": [
        "# Check which branch you're on\r\n",
        "!git branch"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA090PA8PLeH"
      },
      "source": [
        "## Setting up the Python Environment\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myfl1PLy1wZD"
      },
      "source": [
        "# On Google Colab ONLY\r\n",
        "# Reinstall Torch to avoid incompatibility with Cuda 10.1\r\n",
        "\r\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\r\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\r\n",
        "!pip install --ignore-installed torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html > /dev/null\r\n",
        "!pip install git+https://github.com/huggingface/datasets.git@master > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xckt-zuLLVi3"
      },
      "source": [
        "!pip install contractions > /dev/null\r\n",
        "!pip install cltk==0.1.121 > /dev/null\r\n",
        "!pip install nltk==3.5 > /dev/null\r\n",
        "!pip install pyyaml==5.3.1 > /dev/null\r\n",
        "!pip install sacrebleu > /dev/null\r\n",
        "!pip install torchvision==0.7.0 > /dev/null\r\n",
        "!pip install OpenNMT-py > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJPEpWrpEugD"
      },
      "source": [
        "# load notebook environment variables\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3pyyJYjoGwV"
      },
      "source": [
        "# standard library\r\n",
        "import math\r\n",
        "from os import listdir\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "# additional libraries (pip install ..)\r\n",
        "import cltk\r\n",
        "import nltk\r\n",
        "import onmt\r\n",
        "from onmt.utils.misc import set_random_seed\r\n",
        "import pyonmttok\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchtext.data import Dataset\r\n",
        "import yaml\r\n",
        "\r\n",
        "# local libraries\r\n",
        "from src.data_manager import *\r\n",
        "from src.paths import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqRuGHcgpLPX"
      },
      "source": [
        "def set_deterministic(seed: int = 1234):\r\n",
        "    random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    set_random_seed(seed, torch.cuda.is_available())\r\n",
        "\r\n",
        "set_deterministic()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FJ8_RlhiU_N"
      },
      "source": [
        "## Preprocessing and Tokenization\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWn1nklMSqHm"
      },
      "source": [
        "## Data Retrieval\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fokf_1WSxt0"
      },
      "source": [
        "from pandas import read_csv\r\n",
        "\r\n",
        "class HomiliesDataset(Dataset):\r\n",
        "    '''\r\n",
        "    Processes the Homilies Dataset\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "      path{str|Path} -- path to the filename containing the homilies dataset\r\n",
        "      rever\r\n",
        "    '''\r\n",
        "    def  __init__(self, path, reverse=False):\r\n",
        "        df = read_csv (path)\r\n",
        "        self.src = list(df['text'])\r\n",
        "        self.src_key = 't_old'\r\n",
        "        self.tgt = list(df['translation'])\r\n",
        "        self.tgt_key = 't_mod'\r\n",
        "\r\n",
        "        if reverse:\r\n",
        "            self.src, self.tgt, self.src_key = self.tgt, self.src\r\n",
        "            self.src_key, self.tgt_key = self.tgt_key, self.src_key\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        return self.src[index], self.tgt[index]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.src)\r\n",
        "\r\n",
        "    def bible_format(self, training: float = 0.7, valid: float = 0.0) -> {str : {str : [str]}}:\r\n",
        "        '''\r\n",
        "        Returns the dataset formatted similar to the bible datasets to allow\r\n",
        "        common operations.\r\n",
        "\r\n",
        "        Keys are accessed as t_old and t_mod to access the versions\r\n",
        "\r\n",
        "        Arguments:\r\n",
        "            training{float} -- perentage of training data\r\n",
        "            valid{float} -- percentage of data set aside for validation, rest is test data\r\n",
        "        '''\r\n",
        "        dataset = { 'training': { self.src_key : [], self.tgt_key: []}, \r\n",
        "                    'validation': { self.src_key : [], self.tgt_key: []}, \r\n",
        "                    'test': { self.src_key : [], self.tgt_key: []} \r\n",
        "                  }\r\n",
        "\r\n",
        "        n = len(self)\r\n",
        "        train_size = int(training * n)\r\n",
        "        valid_size = int(valid * n)\r\n",
        "        test_size  = n - train_size - valid_size\r\n",
        "        train, valid, test = torch.utils.data.random_split(\r\n",
        "                                                          self, \r\n",
        "                                                          [\r\n",
        "                                                           train_size, \r\n",
        "                                                           valid_size, \r\n",
        "                                                           test_size\r\n",
        "                                                           ])\r\n",
        "        src_train, tgt_train = zip(*train)\r\n",
        "        src_valid, tgt_valid = zip(*valid)\r\n",
        "        src_test, tgt_test = zip(*test)\r\n",
        "\r\n",
        "        dataset['training'][self.src_key] = list(src_train)\r\n",
        "        dataset['training'][self.tgt_key] = list(tgt_train)\r\n",
        "\r\n",
        "        dataset['validation'][self.src_key] = list(src_valid)\r\n",
        "        dataset['validation'][self.tgt_key] = list(tgt_valid)\r\n",
        "\r\n",
        "        dataset['test'][self.src_key] = list(src_test)\r\n",
        "        dataset['test'][self.tgt_key] = list(tgt_test)\r\n",
        "\r\n",
        "        return dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rBaibtnSnz0"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLmGH83poeo4"
      },
      "source": [
        "import cltk\r\n",
        "from cltk.corpus.middle_english.alphabet import normalize_middle_english\r\n",
        "from cltk.phonology.old_english.phonology import Word\r\n",
        "from typing import Union\r\n",
        "\r\n",
        "def _normalize(text: str, language_code: str):\r\n",
        "    if language_code == 'ang':\r\n",
        "        # old english\r\n",
        "        DONT_NORMALIZE = '!?.&,:;\"'\r\n",
        "        normalized_words = list()\r\n",
        "        for word in text.split():\r\n",
        "            if len(word) == 0:\r\n",
        "                continue\r\n",
        "\r\n",
        "            if word[-1] in DONT_NORMALIZE:\r\n",
        "                normalized_words.append(Word(word[:-1]).ascii_encoding() + word[-1])\r\n",
        "            else:\r\n",
        "                normalized_words.append(Word(word).ascii_encoding())\r\n",
        "\r\n",
        "        return ' '.join(normalized_words)\r\n",
        "    elif language_code == 'enm':\r\n",
        "        # middle english\r\n",
        "        return normalize_middle_english(text, to_lower=False, alpha_conv=True, punct=False)\r\n",
        "    return text\r\n",
        "\r\n",
        "def tokenizer(text: str, language_code: str, **kwargs: bool) -> [str]:\r\n",
        "    tok = pyonmttok.Tokenizer(\"aggressive\", joiner_annotate=True, **kwargs)\r\n",
        "    tokens, _ = tok.tokenize(_normalize(text, language_code))\r\n",
        "    return tokens\r\n",
        "\r\n",
        "def write_tokenized_dataset(dataset: {str: {str: [str]}}, source: str, source_language_code: str, target: str, target_language_code: str, file_paths: {str, Union[str, Path], Union[str, Path]}, token_kwargs: {str: bool} = {}) -> None:\r\n",
        "    \"\"\"\r\n",
        "    Given a dataset, tokenizes and writes the contents according to it's file path\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "      dataset {{str: [str]}} -- dataset returned from create_datasets\r\n",
        "      file_paths - dictionary with key as the dataset-type (training, validation, test), item as (path to source, path to target)\r\n",
        "      token_kwargs {{str: bool}} -- kwargs for the tokenizer (case_markup, etc.)\r\n",
        "    \"\"\"\r\n",
        "    for dataset_t in file_paths.keys():\r\n",
        "        src_path, tgt_path = file_paths[dataset_t]\r\n",
        "        with open(src_path, mode='w+', encoding='utf-8') as src, open(tgt_path, mode='w+', encoding='utf-8') as tgt:\r\n",
        "            src.write('\\n'.join([\" \".join(tokenizer(l, source_language_code, **token_kwargs)) for l in dataset[dataset_t][source]]))\r\n",
        "            tgt.write('\\n'.join([\" \".join(tokenizer(l, target_language_code, **token_kwargs)) for l in dataset[dataset_t][target]]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPrbGwuRQQJF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDxEfQtt20T7",
        "outputId": "b3fd4a86-b733-41b3-ca1d-1fe6257a9306"
      },
      "source": [
        "# Check if GPU is active\r\n",
        "# If not, go to \"Runtime\" menu > \"Change runtime type\" > \"GPU\"\r\n",
        "\r\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-a1087da7-91a4-5663-9289-2522f57d179b)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmW12nkB21K-",
        "outputId": "d8fd56e8-fa80-448b-d315-4cad2ce364cf"
      },
      "source": [
        "# Make sure the GPU is visable to PyTorch\r\n",
        "import torch\r\n",
        "\r\n",
        "gpu_id = torch.cuda.current_device()\r\n",
        "print(torch.cuda.is_available())\r\n",
        "print(torch.cuda.get_device_name(gpu_id))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Bd9FKIg-Ml"
      },
      "source": [
        "def build_and_train(config_path):\r\n",
        "    # build and store vocab in run folder\r\n",
        "    !onmt_build_vocab -config \"{config_path}\" -n_sample -1\r\n",
        "    # begin training\r\n",
        "    !onmt_train -config \"{config_path}\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUZIeeDNlJJD"
      },
      "source": [
        "# Translation and Evaluation\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/translate.html) for more info on translation parameters\r\n",
        "\r\n",
        "Evaluatation using BLEU and METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwt4xA_EnMmG"
      },
      "source": [
        "from datasets import list_metrics, load_metric\r\n",
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "from nltk.translate import meteor\r\n",
        "\r\n",
        "def compute_score(candidate_verses: [str], reference_verses: [str], metric_name: str = 'sacrebleu') -> float:\r\n",
        "    metric = load_metric(metric_name)\r\n",
        "    # if it's sacrebleu, need to reformat\r\n",
        "    if metric_name == 'sacrebleu':\r\n",
        "        reference_verses = [[r] for r in reference_verses]\r\n",
        "    \r\n",
        "    if len(candidate_verses) < len(reference_verses):\r\n",
        "        print(\"candidate verses is less than reference verses, trimming reference to fit\")\r\n",
        "        reference_verses = reference_verses[:-1]\r\n",
        "\r\n",
        "    metric.add_batch(predictions = candidate_verses, references = reference_verses)\r\n",
        "    \r\n",
        "    return metric.compute()\r\n",
        "\r\n",
        "def get_detokenized_file(filename: Union[str, Path], tokenize: pyonmttok.Tokenizer) -> [str]:\r\n",
        "    with open(filename, encoding='utf-8') as f:\r\n",
        "        # Add line to strip empty lines\r\n",
        "        lines = [tokenize.detokenize(line.rstrip('\\n').split(' ')) for line in f]\r\n",
        "        if lines[-1] == '':\r\n",
        "            lines = lines[:-1]\r\n",
        "\r\n",
        "        return lines\r\n",
        "\r\n",
        "def get_score(metric_name: str, value: {str: float}) -> None:\r\n",
        "    if metric_name == 'sacrebleu':\r\n",
        "        return value['score']\r\n",
        "    elif metric_name == 'meteor':\r\n",
        "        return value['meteor']\r\n",
        "\r\n",
        "def evaluate(models: Union[str, Path], source: Union[str, Path], target: Union[str, Path], eval_metrics: [str], token_kwargs: {str:bool},  max_length: int, beam_size: 5, save_folder='./predictions', verbose=True) -> {str: {str: {}}}:\r\n",
        "    tokenize = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "    # detokenize the reference file that has been tokenized\r\n",
        "    # (this ensures that any normalization techniques used do not effect the scoring)\r\n",
        "    references = get_detokenized_file(target, tokenize)\r\n",
        "  \r\n",
        "    scores = dict() \r\n",
        "    for m in models:\r\n",
        "        # get the model name\r\n",
        "        model_name = m.name[:-3] if isinstance(m, Path) else m.rsplit('(\\\\|\\/)')[-1][:-3]\r\n",
        "\r\n",
        "        filename = f\"{save_folder}/{model_name}_pred.txt\"\r\n",
        "        \r\n",
        "        # Call the translate script to generate token predictions\r\n",
        "        !onmt_translate -model \"{m}\" -src \"{source}\" -output \"{filename}\" -min_length 1 -max_length \"{max_length}\" -beam_size \"{beam_size}\" -gpu 0 \r\n",
        "        \r\n",
        "        # Retrieve candidate sentences\r\n",
        "        candidates = get_detokenized_file(filename, tokenize)\r\n",
        "        \r\n",
        "        print(f'{model_name} SCORE:')\r\n",
        "\r\n",
        "        metrics = dict()\r\n",
        "        for eval_name in eval_metrics:\r\n",
        "            eval_score = compute_score(candidates, references, eval_name)\r\n",
        "            if verbose:\r\n",
        "                print(f'\\t{eval_name} = {get_score(eval_name, eval_score):.4f}')\r\n",
        "            metrics[eval_name] = eval_score\r\n",
        "        scores[model_name] = metrics\r\n",
        "\r\n",
        "    return scores"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHfn46hoA8bw"
      },
      "source": [
        "# Configuring the Data, Model, and Training Parameters\r\n",
        "Generate a YAML file that contains all the hyperparameters and system variables necessary to build the vocab, build, and train the model.\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/build_vocab.html) for more info on building vocab\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/train.html) for more info about building the model and training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OT26GbF_Tj"
      },
      "source": [
        "# declare the config folder to store all the yaml files\r\n",
        "CONFIG_NAME = 'openmt-config'\r\n",
        "!mkdir -p \"{CONFIG_NAME}\"\r\n",
        "CONFIG_PATH = Path(CONFIG_NAME)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqaPzHBpCpZG"
      },
      "source": [
        "## Middle and Modern English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G-C-dD0EoHQ"
      },
      "source": [
        "### Middle to Modern\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWdU14UyBZIi"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "ENM2MOD_TRANSLATE_NAME = 'enm2mod'\r\n",
        "!mkdir -p '{ENM2MOD_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "ENM2MOD_TRANSLATE_PATH = Path(ENM2MOD_TRANSLATE_NAME)\r\n",
        "ENM2MOD_RUN_PATH = ENM2MOD_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{ENM2MOD_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables\r\n",
        "ENM2MOD_SOURCE_VER = 't_wyc'\r\n",
        "ENM2MOD_SRC_LANG_CODE = 'enm'\r\n",
        "ENM2MOD_TARGET_VER = 't_kjv'\r\n",
        "ENM2MOD_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzd-aZpnBczZ"
      },
      "source": [
        "# Generate splits and write to files\r\n",
        "versions = get_bible_versions_by_file_name([ENM2MOD_SOURCE_VER, ENM2MOD_TARGET_VER])\r\n",
        "\r\n",
        "datasets = create_datasets(versions, .82, \r\n",
        "                preprocess_operations = [preprocess_filter_num_words(MAX_SENTENCE_LENGTH),\r\n",
        "                                         preprocess_expand_contractions(),\r\n",
        "                                         preprocess_filter_num_sentences(),\r\n",
        "                ]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elj5pmCtBN7X"
      },
      "source": [
        "ENM2MOD_SRC_EXT = ENM2MOD_SOURCE_VER[2:]\r\n",
        "ENM2MOD_TGT_EXT = ENM2MOD_TARGET_VER[2:]\r\n",
        "\r\n",
        "\r\n",
        "enm2mod_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-train.{ENM2MOD_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-valid.{ENM2MOD_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-test.{ENM2MOD_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoqCvH6iogUc"
      },
      "source": [
        "write_tokenized_dataset(datasets, ENM2MOD_SOURCE_VER, ENM2MOD_SRC_LANG_CODE, ENM2MOD_TARGET_VER, ENM2MOD_TGT_LANG_CODE, enm2mod_file_paths, token_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5VQ6ZPA2yV"
      },
      "source": [
        "ENM2MOD_SRC_VOCAB_PATH = ENM2MOD_RUN_PATH / 'vocab.src'\r\n",
        "ENM2MOD_TGT_VOCAB_PATH = ENM2MOD_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "enm2mod_yaml = 'enm2mod.yaml'\r\n",
        "\r\n",
        "ENM2MOD_MODEL_PATH = ENM2MOD_RUN_PATH / 'models'\r\n",
        "ENM2MOD_MODEL_PREFIX = 'enm2mod'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTEGa-fAzej"
      },
      "source": [
        "config =  f'''# {enm2mod_yaml}\r\n",
        "save_data: {ENM2MOD_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {ENM2MOD_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {ENM2MOD_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {enm2mod_file_paths['training'][0]}\r\n",
        "        path_tgt: {enm2mod_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {enm2mod_file_paths['validation'][0]}\r\n",
        "        path_tgt: {enm2mod_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {ENM2MOD_MODEL_PATH / ENM2MOD_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "# early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {ENM2MOD_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 1024\r\n",
        "word_vec_size: 256\r\n",
        "dropout: 0.5\r\n",
        "attn_dropout: 0.3\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / enm2mod_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw90EslMG2ZP"
      },
      "source": [
        "build_and_train(CONFIG_PATH / enm2mod_yaml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvDyin8CBtTt"
      },
      "source": [
        "# retrieve the models\r\n",
        "enm2mod_models = [ ENM2MOD_MODEL_PATH / f for f in listdir(ENM2MOD_MODEL_PATH) if f.startswith(ENM2MOD_MODEL_PREFIX)]\r\n",
        "\r\n",
        "ENM2MOD_PREDICTIONS_PATH = ENM2MOD_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{ENM2MOD_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']\r\n",
        "\r\n",
        "enm2mod_scores = evaluate(enm2mod_models, \r\n",
        "                          enm2mod_file_paths['test'][0], \r\n",
        "                          enm2mod_file_paths['test'][1], \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          str(ENM2MOD_PREDICTIONS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-80sPpwGlLvL"
      },
      "source": [
        "The best performing model is after 2900 training iterations with early stopping and beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 26.5572\r\n",
        "    METEOR = 0.4481\r\n",
        "\r\n",
        "Interesting note: Adding a capitalization token and keeping punctuation increased both BLEU and METEOR accuracy by 2-4% compared to lowercase without punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkaOH9VmyJJO"
      },
      "source": [
        "#### User Studies Predictions\r\n",
        "\r\n",
        "Generate predictions for the user studies\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a25utt05mPw3"
      },
      "source": [
        "queries = ['In the bigynnyng God made of nouyt heuene and erthe.', \r\n",
        "           'And Adam clepide the name of his wijf Eue, for sche was the moder of alle men lyuynge.', \r\n",
        "           'And the Lord God clepide Adam, and seide to hym, Where art thou?', \r\n",
        "           'Forsothe the Lord hadde mynde of Noe, and of alle lyuynge beestis, and of alle werk beestis, that weren with hym in the schip; and brouyte a wynd on the erthe.', \r\n",
        "           'And whanne God seiy, that the erthe was corrupt, for ech fleisch ether man hadde corrupt his weie on erthe,', \r\n",
        "           'bi tweyne and bi tweyne, male and female entriden to Noe in to the schip, as the Lord comaundide to Noe.', \r\n",
        "           'And sotheli the watrys yeden and decresiden til to the tenthe monethe, for in the tenthe monethe, in the firste dai of the monethe, the coppis of hillis apperiden.', \r\n",
        "           'And God fillide in the seuenthe dai his werk which he made; and he restide in the seuenthe dai fro al his werk which he hadde maad;', \r\n",
        "           'And the erthe brouyte forth greene erbe and makynge seed bi his kynde, and a tre makynge fruyt, and ech hauynge seed by his kynde. And God seiy that it was good.', \r\n",
        "           'And the Lord dide in that nyyt, as Gedeon axide; and drynesse was in the flees aloone, and deew was in al the erthe.', \r\n",
        "           'Also `the trees spaken to the vyne, Come thou, and comaunde to vs.', \r\n",
        "           'Therfor not Y do synne ayens thee, but thou doist yuel ayens me, and bryngist in batels not iust to me; the Lord, iuge of this dai, deme bitwixe the sones of Israel and bitwixe the sones of Amon.', \r\n",
        "           'The trauel of foolis shal turment hem, that kunnen not go in to the citee.', \r\n",
        "           'And if seuene sithis in the dai he do synne ayens thee, and seuene sithis in the dai he be conuertid to thee, and seie, It forthenkith me, foryyue thou hym.', \r\n",
        "           'and seide, Oneli Y knewe you of alle the kynredis of erthe; therfor Y schal visite on you alle youre wickidnessis.', \r\n",
        "           'And he is heed of the bodi of the chirche; which is the bigynnyng and the firste bigetun of deede men, that he holde the firste dignyte in alle thingis.', \r\n",
        "           'And the foure beestis seiden, Amen. And the foure and twenti eldre men fellen doun on her faces, and worschipiden hym that lyueth in to worldis of worldis.', \r\n",
        "           'He brak at noumbre my teeth; he fedde me with aische.', \r\n",
        "           'And if Sathanas be departid ayens hym silf, hou schal his rewme stonde? For ye seien, that Y caste out feendis in Belsabub.', \r\n",
        "           'coueitouse, hiy of bering, proude, blasfemeris, not obedient to fadir and modir, vnkynde,', \r\n",
        "           'Forsothe God seide, Liytis be maad in the firmament of heuene, and departe tho the dai and niyt; and be tho in to signes, and tymes, and daies, and yeeris;', \r\n",
        "           'Isaac dredde bi a greet astonying; and he wondride more, than it mai be bileued, and seide, Who therfor is he which a while ago brouyte to me huntyng takun, and Y eet of alle thingis bifor that thou camest; and Y blesside him? and he schal be blessid.', \r\n",
        "           'And lo! an aungel of the Lord criede fro heuene, and seide, Abraham! Abraham!', \r\n",
        "           'Sotheli Abraham plauntide a wode in Bersabee, and inwardli clepide there the name of euerlastinge God; and he was an erthetiliere ether a comelynge of the lond of Palestynes in many dayes.',\r\n",
        "           'And he helde forth his hond, and took the swerd to sacrifice his sone.', \r\n",
        "           'Abraham turnede ayen to hise children, and thei yeden to Bersabee to gidere, and he dwellide there.', \r\n",
        "           'And whanne ye weren deed in giltis, and in the prepucie of youre fleisch, he quikenyde togidere you with hym;', \r\n",
        "           'Wymmen, be ye sugetis to youre hosebondis, as it bihoueth in the Lord.', \r\n",
        "           'For he that doith iniurie, schal resseyue that that he dide yuele; and acceptacioun of persoones is not anentis God.', \r\n",
        "           'Aristark, prisoner with me, gretith you wel, and Mark, the cosyn of Barnabas, of whom ye han take maundementis; if he come to you, resseyue ye hym;', \r\n",
        "           'But to God and oure fadir be glorie in to worldis of worldis.'\r\n",
        "           ]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubw1aaU6yNYB"
      },
      "source": [
        "# Best Performing Model\r\n",
        "model = ENM2MOD_MODEL_PATH / f'{ENM2MOD_MODEL_PREFIX}_step_2900.pt'\r\n",
        "MIDDLE_TEXT_TOK = DATA_PATH / 'user-studies.enm'\r\n",
        "MIDDLE_TEST_PRED = ENM2MOD_PREDICTIONS_PATH / 'middle-text-pred.txt'\r\n",
        "\r\n",
        "with open(MIDDLE_TEXT_TOK, mode='w+', encoding='utf-8') as f:\r\n",
        "      eval_text = [l.rstrip('\\n') for l in f]\r\n",
        "      f.write('\\n'.join([\" \".join(tokenizer(l, 'enm', **token_kwargs)) for l in queries]))\r\n",
        "\r\n",
        "!onmt_translate -model \"{model}\" -src \"{MIDDLE_TEXT_TOK}\" -output \"{MIDDLE_TEST_PRED}\" -min_length 1 -max_length 60 -beam_size 5 -gpu 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgnAspYUysW9"
      },
      "source": [
        "tokenize = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "hypotheses = get_detokenized_file(MIDDLE_TEST_PRED, tokenize)\r\n",
        "\r\n",
        "for hyp in hypotheses:\r\n",
        "    print(hyp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRLR8eZFT4Go"
      },
      "source": [
        "### Modern to Middle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFbUFqBwGiC2"
      },
      "source": [
        "We can reuse the preprocessing files saved from the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qEGECBoEsqx"
      },
      "source": [
        "MOD2ENM_TRANSLATE_NAME = 'mod2enm'\r\n",
        "!mkdir -p '{MOD2ENM_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "MOD2ENM_TRANSLATE_PATH = Path(MOD2ENM_TRANSLATE_NAME)\r\n",
        "MOD2ENM_RUN_PATH = MOD2ENM_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{MOD2ENM_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables (swap previous run)\r\n",
        "MOD2ENM_SOURCE_VER = 't_kjv'\r\n",
        "MOD2ENM_TARGET_VER = 't_wyc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPcBIfqUE9dg"
      },
      "source": [
        "MOD2ENM_SRC_EXT = MOD2ENM_SOURCE_VER[2:]\r\n",
        "MOD2ENM_TGT_EXT = MOD2ENM_TARGET_VER[2:]\r\n",
        "\r\n",
        "mod2enm_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-train.{MOD2ENM_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-valid.{MOD2ENM_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-test.{MOD2ENM_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4BpV395Sx2X"
      },
      "source": [
        "# datasets are already tokenized by the first run, no need to do again\r\n",
        "# write_tokenized_dataset(datasets, MOD2ENM_SOURCE_VER, ENM2MOD_TGT_LANG_CODE, MOD2ENM_TARGET_VER, ENM2MOD_SRC_LANG_CODE, mod2enm_file_paths, token_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsQxvqJMdRn8"
      },
      "source": [
        "MOD2ENM_SRC_VOCAB_PATH = MOD2ENM_RUN_PATH / 'vocab.src'\r\n",
        "MOD2ENM_TGT_VOCAB_PATH = MOD2ENM_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "mod2enm_yaml = 'mod2enm.yaml'\r\n",
        "\r\n",
        "MOD2ENM_MODEL_PATH = MOD2ENM_RUN_PATH / 'models'\r\n",
        "MOD2ENM_MODEL_PREFIX = 'mod2enm'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzJIRf0IF0A9"
      },
      "source": [
        "config =  f'''# {mod2enm_yaml}\r\n",
        "save_data: {MOD2ENM_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {MOD2ENM_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {MOD2ENM_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {mod2enm_file_paths['training'][0]}\r\n",
        "        path_tgt: {mod2enm_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {mod2enm_file_paths['validation'][0]}\r\n",
        "        path_tgt: {mod2enm_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {MOD2ENM_MODEL_PATH / MOD2ENM_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {MOD2ENM_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 1024\r\n",
        "word_vec_size: 256\r\n",
        "dropout: 0.5\r\n",
        "attn_dropout: 0.3\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / mod2enm_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yfSnvqCG5ny"
      },
      "source": [
        "build_and_train(CONFIG_PATH / mod2enm_yaml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR9OVz2kASQU"
      },
      "source": [
        "# retrieve the models\r\n",
        "mod2enm_model_paths = [ MOD2ENM_MODEL_PATH / f for f in listdir(MOD2ENM_MODEL_PATH) if f.startswith(MOD2ENM_MODEL_PREFIX)]\r\n",
        "\r\n",
        "MOD2ENM_PREDICTIONS_PATH = MOD2ENM_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{MOD2ENM_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "# Don't use meteor on non-english translations\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmySfcAznh7H"
      },
      "source": [
        "mod2enm_scores = evaluate(mod2enm_model_paths, \r\n",
        "                          mod2enm_file_paths['test'][0], \r\n",
        "                          mod2enm_file_paths['test'][1], \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          MOD2ENM_PREDICTIONS_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE0IJbgH3VC7"
      },
      "source": [
        "Using BLEU Scoring, the best performing model is after 3000 training iterations at beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 28.4447\r\n",
        "    METEOR = 0.4577"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgOAA9XAYkIc"
      },
      "source": [
        "## Old and Modern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7bLM4MoYsG8"
      },
      "source": [
        "### Old to Modern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-kOLWJvYyn2"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "ANG2MOD_TRANSLATE_NAME = 'ang2mod'\r\n",
        "!mkdir -p '{ANG2MOD_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "ANG2MOD_TRANSLATE_PATH = Path(ANG2MOD_TRANSLATE_NAME)\r\n",
        "ANG2MOD_RUN_PATH = ANG2MOD_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{ANG2MOD_RUN_PATH}\"\r\n",
        "\r\n",
        "## Dataset Variables\r\n",
        "# For the Homilies Dataset\r\n",
        "ANG2MOD_HOM_SOURCE_VER = 't_old'\r\n",
        "ANG2MOD_HOM_SRC_LANG_CODE = 'ang'\r\n",
        "ANG2MOD_HOM_TARGET_VER = 't_mod'\r\n",
        "ANG2MOD_HOM_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "# For the Bible Dataset\r\n",
        "ANG2MOD_SOURCE_VER = 't_alf_wsg'\r\n",
        "ANG2MOD_SRC_LANG_CODE = 'ang'\r\n",
        "ANG2MOD_TARGET_VER = 't_kjv'\r\n",
        "ANG2MOD_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HhPnhfjHJgm"
      },
      "source": [
        "homilies_raw = HomiliesDataset(MISC_TEXTS_PATH / 't_hom.csv')\r\n",
        "hom_dataset = homilies_raw.bible_format(training=0.7, valid=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnDO3eUdke86"
      },
      "source": [
        "print(\"# training verses: \\t\", len(hom_dataset['training']['t_old']))\r\n",
        "print(\"# training verses: \\t\", len(hom_dataset['validation']['t_old']))\r\n",
        "print(\"# training verses: \\t\", len(hom_dataset['test']['t_old']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TSkJm1JHIpA"
      },
      "source": [
        "# Generate splits and write to files\r\n",
        "versions = get_bible_versions_by_file_name([ANG2MOD_SOURCE_VER, ANG2MOD_TARGET_VER])\r\n",
        "\r\n",
        "datasets = create_datasets(versions, 0.8, \r\n",
        "                preprocess_operations = [preprocess_filter_num_words(MAX_SENTENCE_LENGTH),\r\n",
        "                                         preprocess_expand_contractions(),\r\n",
        "                ], write_files=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pos70JdrILEh"
      },
      "source": [
        "ANG2MOD_HOM_SRC_EXT = ANG2MOD_HOM_SOURCE_VER[2:]\r\n",
        "ANG2MOD_HOM_TGT_EXT = ANG2MOD_HOM_TARGET_VER[2:]\r\n",
        "\r\n",
        "ang2mod_hom_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'hom-train.{ANG2MOD_HOM_SRC_EXT}', DATA_PATH / f'hom-train.{ANG2MOD_HOM_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'hom-valid.{ANG2MOD_HOM_SRC_EXT}', DATA_PATH / f'hom-valid.{ANG2MOD_HOM_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'hom-test.{ANG2MOD_HOM_SRC_EXT}', DATA_PATH / f'hom-test.{ANG2MOD_HOM_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "ANG2MOD_SRC_EXT = ANG2MOD_SOURCE_VER[2:]\r\n",
        "ANG2MOD_TGT_EXT = ANG2MOD_TARGET_VER[2:]\r\n",
        "\r\n",
        "ang2mod_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{ANG2MOD_SRC_EXT}', DATA_PATH / f'bible-train.{ANG2MOD_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{ANG2MOD_SRC_EXT}', DATA_PATH / f'bible-valid.{ANG2MOD_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{ANG2MOD_SRC_EXT}', DATA_PATH / f'bible-test.{ANG2MOD_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efy6XxQTS9Gh"
      },
      "source": [
        "write_tokenized_dataset(hom_dataset, ANG2MOD_HOM_SOURCE_VER, ANG2MOD_HOM_SRC_LANG_CODE, ANG2MOD_HOM_TARGET_VER, ANG2MOD_HOM_TGT_LANG_CODE, ang2mod_hom_file_paths, token_kwargs)\r\n",
        "write_tokenized_dataset(datasets, ANG2MOD_SOURCE_VER, ANG2MOD_SRC_LANG_CODE, ANG2MOD_TARGET_VER, ANG2MOD_TGT_LANG_CODE, ang2mod_file_paths, token_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjiQNv3UKKHc"
      },
      "source": [
        "# Need to combine the validation sets for training\r\n",
        "COMBINED_VALID_SRC = DATA_PATH / f'combined-valid.{ANG2MOD_HOM_SRC_EXT}.{ANG2MOD_SRC_EXT}'\r\n",
        "COMBINED_VALID_TGT = DATA_PATH / f'combined-valid.{ANG2MOD_HOM_TGT_EXT}.{ANG2MOD_TGT_EXT}'\r\n",
        "COMBINED_TEST_SRC = DATA_PATH / f'combined-test.{ANG2MOD_HOM_SRC_EXT}.{ANG2MOD_SRC_EXT}'\r\n",
        "COMBINED_TEST_TGT = DATA_PATH / f'combined-test.{ANG2MOD_HOM_TGT_EXT}.{ANG2MOD_TGT_EXT}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFs0vVD1sRB8"
      },
      "source": [
        "with open(COMBINED_VALID_SRC, mode='w+', encoding='utf-8') as f:\r\n",
        "    with open(ang2mod_hom_file_paths['validation'][0], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "    with open(ang2mod_file_paths['validation'][0], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "\r\n",
        "with open(COMBINED_VALID_TGT, mode='w+', encoding='utf-8') as f:\r\n",
        "    with open(ang2mod_hom_file_paths['validation'][1], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "    with open(ang2mod_file_paths['validation'][1], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaE1zjf0sSF6"
      },
      "source": [
        "with open(COMBINED_TEST_SRC, mode='w+', encoding='utf-8') as f:\r\n",
        "    with open(ang2mod_hom_file_paths['test'][0], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "    with open(ang2mod_file_paths['test'][0], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "\r\n",
        "with open(COMBINED_TEST_TGT, mode='w+', encoding='utf-8') as f:\r\n",
        "    with open(ang2mod_hom_file_paths['test'][1], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))\r\n",
        "    with open(ang2mod_file_paths['test'][1], encoding='utf-8') as hom:\r\n",
        "        f.write('\\n'.join([l.rstrip('\\n') for l in hom if l != '\\n']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5UQfa5VIP11"
      },
      "source": [
        "ANG2MOD_SRC_VOCAB_PATH = ANG2MOD_RUN_PATH / 'vocab.src'\r\n",
        "ANG2MOD_TGT_VOCAB_PATH = ANG2MOD_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "ang2mod_yaml = 'ang2mod.yaml'\r\n",
        "\r\n",
        "ANG2MOD_MODEL_PATH = ANG2MOD_RUN_PATH / 'models'\r\n",
        "ANG2MOD_MODEL_PREFIX = 'ang2mod'"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXPANEslISd7"
      },
      "source": [
        "config =  f'''# {ang2mod_yaml}\r\n",
        "save_data: {ANG2MOD_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {ANG2MOD_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {ANG2MOD_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {ang2mod_hom_file_paths['training'][0]}\r\n",
        "        path_tgt: {ang2mod_hom_file_paths['training'][1]}\r\n",
        "        transforms: [filtertoolong]\r\n",
        "        weight: 1\r\n",
        "    corpus_2:\r\n",
        "       path_src: {ang2mod_file_paths['training'][0]}\r\n",
        "       path_tgt: {ang2mod_file_paths['training'][1]}\r\n",
        "       transforms: [filtertoolong]\r\n",
        "       weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {COMBINED_VALID_SRC}\r\n",
        "        path_tgt: {COMBINED_VALID_TGT}\r\n",
        "        transforms: [filtertoolong]\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "# Data Transformations\r\n",
        "### Filter\r\n",
        "src_seq_length: {MAX_SENTENCE_LENGTH}\r\n",
        "tgt_seq_length: {MAX_SENTENCE_LENGTH}\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {ANG2MOD_MODEL_PATH / ANG2MOD_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "# early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {ANG2MOD_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 40\r\n",
        "valid_batch_size: 40\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 128\r\n",
        "dropout: 0.6\r\n",
        "attn_dropout: 0.4\r\n",
        "# global_attention: dot\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / ang2mod_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ado19PtLlDh"
      },
      "source": [
        "build_and_train(CONFIG_PATH / ang2mod_yaml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBVvZeEb-l2W"
      },
      "source": [
        "# retrieve the models\r\n",
        "ang2mod_models = [ ANG2MOD_MODEL_PATH / f for f in listdir(ANG2MOD_MODEL_PATH) if f.startswith(ANG2MOD_MODEL_PREFIX)]\r\n",
        "\r\n",
        "ANG2MOD_PREDICTIONS_PATH = ANG2MOD_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{ANG2MOD_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNwnhwMa-oIY"
      },
      "source": [
        "ang2mod_scores = evaluate(ang2mod_models, \r\n",
        "                          COMBINED_TEST_SRC, \r\n",
        "                          COMBINED_TEST_TGT, \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          str(ANG2MOD_PREDICTIONS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JpSXB57egV8"
      },
      "source": [
        "The best performing model is after 3100 training iterations with early stopping and beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 16.8312\r\n",
        "    METEOR = 0.3316"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhYghOuQewS1"
      },
      "source": [
        "#### User Studies Predictions\r\n",
        "\r\n",
        "Generate predictions for the user studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98rqNcsWe8Ps"
      },
      "source": [
        "queries = ['ON angynne gesceop God heofonan & eoran.', \r\n",
        "           'a gesceop Adam naman his wife, Eua, t is lif, for ane heo is ealra libbendra modor.', \r\n",
        "           'God clypode a Adam, & cw: Adam, hwr eart u.', \r\n",
        "           '& GOD a gemunde Noes fare & ra nytena e him midwron, & asende wind ofer eoran, & a wteruwurdon gewanode.', \r\n",
        "           'a geseah God t seo eore ws gewemmed, for an elc flsc gewemde his weg ofer eoran.', \r\n",
        "           'comon to Noe in to am arce, swa swa God bebead.', \r\n",
        "           '& a wteru toeodan & wanodon of one teoan mon, & onam teoan mone teowedon ra muntacnollas.', \r\n",
        "           '& God a gefylde on one seofoan dg his weorc e heworhte. & he gereste hine on one seofoan dg fram eallumam weorcum e he gefremode.', \r\n",
        "           '& seo eore forteah growende wyrta & sd berende be hyrecynne & treow wstm wyrcende & gehwilcsd hbbende fter his hiwe; God geseah a t hit godws.', \r\n",
        "           'God cw a solice: Beo nu leoht on re heofenanfstnysse, & todlan dg & nihte, & beon to tacnum& to tidum & to dagum & to gearum.', \r\n",
        "           'Mid am e he wolde t weorc begynnan, a clypode Godesengel ardlice of heofonum, Abraham; Heandwyrde sona.', \r\n",
        "           '& hys swurd ateah t he hyne geoffrode on a ealdanwisan.'\r\n",
        "           ]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSIwONzezcO"
      },
      "source": [
        "model = ANG2MOD_MODEL_PATH / f'{ANG2MOD_MODEL_PREFIX}_step_3100.pt'\r\n",
        "OLD_TEXT_TOK = DATA_PATH / 'user-studies.ang'\r\n",
        "OLD_TEST_PRED = ANG2MOD_PREDICTIONS_PATH / 'old-text-pred.txt'\r\n",
        "\r\n",
        "with open(OLD_TEXT_TOK, mode='w+', encoding='utf-8') as f:\r\n",
        "      eval_text = [l.rstrip('\\n') for l in f]\r\n",
        "      f.write('\\n'.join([\" \".join(tokenizer(l, 'enm', **token_kwargs)) for l in queries]))\r\n",
        "\r\n",
        "!onmt_translate -model \"{model}\" -src \"{OLD_TEXT_TOK}\" -output \"{OLD_TEST_PRED}\" -min_length 1 -max_length \"{MAX_SENTENCE_LENGTH}\" -beam_size 5 -gpu 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNG5jadCe70T"
      },
      "source": [
        "tokenize = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "hypotheses = get_detokenized_file(OLD_TEST_PRED, tokenize)\r\n",
        "\r\n",
        "for hyp in hypotheses:\r\n",
        "    print(hyp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGa7Q7FNYxMf"
      },
      "source": [
        "### Modern to Old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP2qCNTsYzDe"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "MOD2ANG_TRANSLATE_NAME = 'mod2ang'\r\n",
        "!mkdir -p '{MOD2ANG_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "MOD2ANG_TRANSLATE_PATH = Path(MOD2ANG_TRANSLATE_NAME)\r\n",
        "MOD2ANG_RUN_PATH = MOD2ANG_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{MOD2ANG_RUN_PATH}\"\r\n",
        "\r\n",
        "## Dataset Variables\r\n",
        "# For the Homilies Dataset\r\n",
        "MOD2ANG_HOM_SOURCE_VER = 't_mod'\r\n",
        "MOD2ANG_HOM_SRC_LANG_CODE = 'eng'\r\n",
        "MOD2ANG_HOM_TARGET_VER = 't_old'\r\n",
        "MOD2ANG_HOM_TGT_LANG_CODE = 'ang'\r\n",
        "\r\n",
        "# For the Bible Dataset\r\n",
        "MOD2ANG_SOURCE_VER = 't_kjv'\r\n",
        "MOD2ANG_SRC_LANG_CODE = 'eng'\r\n",
        "MOD2ANG_TARGET_VER = 't_alf_wsg'\r\n",
        "MOD2ANG_TGT_LANG_CODE = 'ang'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo9Km425jggi"
      },
      "source": [
        "MOD2ANG_HOM_SRC_EXT = MOD2ANG_HOM_SOURCE_VER[2:]\r\n",
        "MOD2ANG_HOM_TGT_EXT = MOD2ANG_HOM_TARGET_VER[2:]\r\n",
        "\r\n",
        "mod2ang_hom_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'hom-train.{MOD2ANG_HOM_SRC_EXT}', DATA_PATH / f'hom-train.{MOD2ANG_HOM_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'hom-valid.{MOD2ANG_HOM_SRC_EXT}', DATA_PATH / f'hom-valid.{MOD2ANG_HOM_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'hom-test.{MOD2ANG_HOM_SRC_EXT}', DATA_PATH / f'hom-test.{MOD2ANG_HOM_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "MOD2ANG_SRC_EXT = MOD2ANG_SOURCE_VER[2:]\r\n",
        "MOD2ANG_TGT_EXT = MOD2ANG_TARGET_VER[2:]\r\n",
        "\r\n",
        "mod2ang_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{MOD2ANG_SRC_EXT}', DATA_PATH / f'bible-train.{MOD2ANG_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{MOD2ANG_SRC_EXT}', DATA_PATH / f'bible-valid.{MOD2ANG_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{MOD2ANG_SRC_EXT}', DATA_PATH / f'bible-test.{MOD2ANG_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlYz3qtej2PB"
      },
      "source": [
        "# Need to combine the validation sets for training\r\n",
        "COMBINED_VALID_SRC = DATA_PATH / f'combined-valid.{MOD2ANG_HOM_SRC_EXT}.{MOD2ANG_SRC_EXT}'\r\n",
        "COMBINED_VALID_TGT = DATA_PATH / f'combined-valid.{MOD2ANG_HOM_TGT_EXT}.{MOD2ANG_TGT_EXT}'\r\n",
        "COMBINED_TEST_SRC = DATA_PATH / f'combined-test.{MOD2ANG_HOM_SRC_EXT}.{MOD2ANG_SRC_EXT}'\r\n",
        "COMBINED_TEST_TGT = DATA_PATH / f'combined-test.{MOD2ANG_HOM_TGT_EXT}.{MOD2ANG_TGT_EXT}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS0__xavkBf5"
      },
      "source": [
        "MOD2ANG_SRC_VOCAB_PATH = MOD2ANG_RUN_PATH / 'vocab.src'\r\n",
        "MOD2ANG_TGT_VOCAB_PATH = MOD2ANG_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "mod2ang_yaml = 'mod2ang.yaml'\r\n",
        "\r\n",
        "MOD2ANG_MODEL_PATH = ANG2MOD_RUN_PATH / 'models'\r\n",
        "MOD2ANG_MODEL_PREFIX = 'mod2ang'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFOHsC9bkJ8S"
      },
      "source": [
        "config =  f'''# {mod2ang_yaml}\r\n",
        "save_data: {MOD2ANG_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {MOD2ANG_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {MOD2ANG_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {mod2ang_hom_file_paths['training'][0]}\r\n",
        "        path_tgt: {mod2ang_hom_file_paths['training'][1]}\r\n",
        "        transforms: [filtertoolong]\r\n",
        "        weight: 1\r\n",
        "    corpus_2:\r\n",
        "       path_src: {mod2ang_file_paths['training'][0]}\r\n",
        "       path_tgt: {mod2ang_file_paths['training'][1]}\r\n",
        "       transforms: [filtertoolong]\r\n",
        "       weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {COMBINED_VALID_SRC}\r\n",
        "        path_tgt: {COMBINED_VALID_TGT}\r\n",
        "        transforms: [filtertoolong]\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "# Data Transformations\r\n",
        "### Filter\r\n",
        "src_seq_length: {MAX_SENTENCE_LENGTH}\r\n",
        "tgt_seq_length: {MAX_SENTENCE_LENGTH}\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {MOD2ANG_MODEL_PATH / MOD2ANG_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "# early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {ANG2MOD_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 40\r\n",
        "valid_batch_size: 40\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 128\r\n",
        "dropout: 0.6\r\n",
        "attn_dropout: 0.4\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / mod2ang_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdTZFn_Yyr3Z"
      },
      "source": [
        "build_and_train(CONFIG_PATH / mod2ang_yaml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFt9nbXgmmpj"
      },
      "source": [
        "# retrieve the models\r\n",
        "mod2ang_models = [ MOD2ANG_MODEL_PATH / f for f in listdir(MOD2ANG_MODEL_PATH) if f.startswith(MOD2ANG_MODEL_PREFIX)]\r\n",
        "\r\n",
        "MOD2ANG_PREDICTIONS_PATH = MOD2ANG_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{MOD2ANG_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AG50ke1mx0B"
      },
      "source": [
        "mod2ang_scores = evaluate(mod2ang_models, \r\n",
        "                          COMBINED_TEST_SRC, \r\n",
        "                          COMBINED_TEST_TGT, \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          str(MOD2ANG_PREDICTIONS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoP0Dj9o5w9P"
      },
      "source": [
        "The best performing model is after 2800 training iterations with early stopping and beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 11.1664\r\n",
        "    METEOR = 0.2554"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqQLASVRDkI"
      },
      "source": [
        "## Modern to Modern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sehy2zifYKC7"
      },
      "source": [
        "### KJV to BBE\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-xsP39YWYy"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "KJV2BBE_TRANSLATE_NAME = 'kjv2bbe'\r\n",
        "!mkdir -p '{KJV2BBE_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "KJV2BBE_TRANSLATE_PATH = Path(KJV2BBE_TRANSLATE_NAME)\r\n",
        "KJV2BBE_RUN_PATH = KJV2BBE_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{KJV2BBE_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables\r\n",
        "KJV2BBE_SOURCE_VER = 't_kjv'\r\n",
        "KJV2BBE_SRC_LANG_CODE = 'eng'\r\n",
        "KJV2BBE_TARGET_VER = 't_bbe'\r\n",
        "KJV2BBE_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb4WzO-NYlOi"
      },
      "source": [
        "# Generate splits and write to files\r\n",
        "versions = get_bible_versions_by_file_name([KJV2BBE_SOURCE_VER, KJV2BBE_TARGET_VER])\r\n",
        "\r\n",
        "datasets = create_datasets(versions, .82, \r\n",
        "                preprocess_operations = [preprocess_filter_num_words(MAX_SENTENCE_LENGTH),\r\n",
        "                                         preprocess_expand_contractions(),\r\n",
        "                                         preprocess_filter_num_sentences(),\r\n",
        "                ]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2E96kdFYriB"
      },
      "source": [
        "KJV2BBE_SRC_EXT = KJV2BBE_SOURCE_VER[2:]\r\n",
        "KJV2BBE_TGT_EXT = KJV2BBE_TARGET_VER[2:]\r\n",
        "\r\n",
        "\r\n",
        "kjv2bbe_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{KJV2BBE_SRC_EXT}', DATA_PATH / f'bible-train.{KJV2BBE_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{KJV2BBE_SRC_EXT}', DATA_PATH / f'bible-valid.{KJV2BBE_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{KJV2BBE_SRC_EXT}', DATA_PATH / f'bible-test.{KJV2BBE_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yfuACDqYuQh"
      },
      "source": [
        "write_tokenized_dataset(datasets, KJV2BBE_SOURCE_VER, KJV2BBE_SRC_LANG_CODE, KJV2BBE_TARGET_VER, KJV2BBE_TGT_LANG_CODE, kjv2bbe_file_paths, token_kwargs)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3yz7ijRYwuD"
      },
      "source": [
        "KJV2BBE_SRC_VOCAB_PATH = KJV2BBE_RUN_PATH / 'vocab.src'\r\n",
        "KJV2BBE_TGT_VOCAB_PATH = KJV2BBE_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "kjv2bbe_yaml = 'kjv2bbe.yaml'\r\n",
        "\r\n",
        "KJV2BBE_MODEL_PATH = KJV2BBE_RUN_PATH / 'models'\r\n",
        "KJV2BBE_MODEL_PREFIX = 'kjv2bbe'"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxcgalyY0tD"
      },
      "source": [
        "config =  f'''# {kjv2bbe_yaml}\r\n",
        "save_data: {KJV2BBE_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {KJV2BBE_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {KJV2BBE_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {kjv2bbe_file_paths['training'][0]}\r\n",
        "        path_tgt: {kjv2bbe_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {kjv2bbe_file_paths['validation'][0]}\r\n",
        "        path_tgt: {kjv2bbe_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {KJV2BBE_MODEL_PATH / KJV2BBE_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "# early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {KJV2BBE_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 256\r\n",
        "dropout: 0.5\r\n",
        "attn_dropout: 0.3\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / kjv2bbe_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XiOOKTvY3zI",
        "outputId": "8868d232-4a3d-496a-d4d7-7c8fa45dd503"
      },
      "source": [
        "build_and_train(CONFIG_PATH / kjv2bbe_yaml)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-08 21:56:56,904 INFO] Counter vocab from -1 samples.\n",
            "[2021-03-08 21:56:56,904 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2021-03-08 21:56:56,913 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2021-03-08 21:56:56,916 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 21:56:57,616 INFO] Counters src:10470\n",
            "[2021-03-08 21:56:57,616 INFO] Counters tgt:5083\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_build_vocab\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/build_vocab.py\", line 66, in main\n",
            "    build_vocab_main(opts)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/build_vocab.py\", line 53, in build_vocab_main\n",
            "    save_counter(src_counter, opts.src_vocab)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/build_vocab.py\", line 42, in save_counter\n",
            "    check_path(save_path, exist_ok=opts.overwrite, log=logger.warning)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/utils/misc.py\", line 17, in check_path\n",
            "    raise IOError(f\"path {path} exists, stop.\")\n",
            "OSError: path kjv2bbe/run/vocab.src exists, stop.\n",
            "[2021-03-08 21:56:58,415 INFO] Parsed 2 corpora from -data.\n",
            "[2021-03-08 21:56:58,415 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2021-03-08 21:56:58,415 INFO] Loading vocab from text file...\n",
            "[2021-03-08 21:56:58,415 INFO] Loading src vocabulary from kjv2bbe/run/vocab.src\n",
            "[2021-03-08 21:56:58,438 INFO] Loaded src vocab has 10470 tokens.\n",
            "[2021-03-08 21:56:58,443 INFO] Loading tgt vocabulary from kjv2bbe/run/vocab.tgt\n",
            "[2021-03-08 21:56:58,454 INFO] Loaded tgt vocab has 5083 tokens.\n",
            "[2021-03-08 21:56:58,457 INFO] Building fields with vocab in counters...\n",
            "[2021-03-08 21:56:58,464 INFO]  * tgt vocab size: 5087.\n",
            "[2021-03-08 21:56:58,478 INFO]  * src vocab size: 10472.\n",
            "[2021-03-08 21:56:58,479 INFO]  * src vocab size = 10472\n",
            "[2021-03-08 21:56:58,479 INFO]  * tgt vocab size = 5087\n",
            "[2021-03-08 21:56:58,481 INFO] Building model...\n",
            "[2021-03-08 21:57:00,936 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10472, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5087, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(768, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=5087, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2021-03-08 21:57:00,936 INFO] encoder: 6359040\n",
            "[2021-03-08 21:57:00,936 INFO] decoder: 9425119\n",
            "[2021-03-08 21:57:00,936 INFO] * number of parameters: 15784159\n",
            "2021-03-08 21:57:01.386940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[2021-03-08 21:57:02,932 INFO] Starting training on GPU: [0]\n",
            "[2021-03-08 21:57:02,933 INFO] Start training loop and validate every 100 steps...\n",
            "[2021-03-08 21:57:02,933 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2021-03-08 21:57:02,935 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 21:57:17,869 INFO] Step 100/100000; acc:  11.81; ppl: 209.93; xent: 5.35; lr: 0.00100; 13297/14203 tok/s;     15 sec\n",
            "[2021-03-08 21:57:17,870 INFO] valid's transforms: TransformPipe()\n",
            "[2021-03-08 21:57:17,872 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:580: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1234.)\n",
            "  self.num_layers, self.dropout, self.training, self.bidirectional)\n",
            "[2021-03-08 21:57:23,446 INFO] Validation perplexity: 102.536\n",
            "[2021-03-08 21:57:23,447 INFO] Validation accuracy: 20.8256\n",
            "[2021-03-08 21:57:23,447 INFO] Model is improving ppl: inf --> 102.536.\n",
            "[2021-03-08 21:57:23,447 INFO] Model is improving acc: -inf --> 20.8256.\n",
            "[2021-03-08 21:57:38,343 INFO] Step 200/100000; acc:  24.92; ppl: 72.31; xent: 4.28; lr: 0.00100; 9727/10470 tok/s;     35 sec\n",
            "[2021-03-08 21:57:38,346 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:57:43,958 INFO] Validation perplexity: 49.5582\n",
            "[2021-03-08 21:57:43,958 INFO] Validation accuracy: 28.8797\n",
            "[2021-03-08 21:57:43,959 INFO] Model is improving ppl: 102.536 --> 49.5582.\n",
            "[2021-03-08 21:57:43,959 INFO] Model is improving acc: 20.8256 --> 28.8797.\n",
            "[2021-03-08 21:57:57,194 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 21:57:58,924 INFO] Step 300/100000; acc:  31.16; ppl: 43.00; xent: 3.76; lr: 0.00100; 9715/10408 tok/s;     56 sec\n",
            "[2021-03-08 21:57:58,927 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:58:04,680 INFO] Validation perplexity: 30.8574\n",
            "[2021-03-08 21:58:04,680 INFO] Validation accuracy: 35.7993\n",
            "[2021-03-08 21:58:04,681 INFO] Model is improving ppl: 49.5582 --> 30.8574.\n",
            "[2021-03-08 21:58:04,681 INFO] Model is improving acc: 28.8797 --> 35.7993.\n",
            "[2021-03-08 21:58:19,681 INFO] Step 400/100000; acc:  38.03; ppl: 28.08; xent: 3.34; lr: 0.00100; 9642/10283 tok/s;     77 sec\n",
            "[2021-03-08 21:58:19,684 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:58:25,316 INFO] Validation perplexity: 21.3276\n",
            "[2021-03-08 21:58:25,317 INFO] Validation accuracy: 42.2414\n",
            "[2021-03-08 21:58:25,317 INFO] Model is improving ppl: 30.8574 --> 21.3276.\n",
            "[2021-03-08 21:58:25,317 INFO] Model is improving acc: 35.7993 --> 42.2414.\n",
            "[2021-03-08 21:58:40,390 INFO] Step 500/100000; acc:  43.15; ppl: 20.62; xent: 3.03; lr: 0.00100; 9619/10337 tok/s;     97 sec\n",
            "[2021-03-08 21:58:40,393 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:58:45,977 INFO] Validation perplexity: 16.4002\n",
            "[2021-03-08 21:58:45,978 INFO] Validation accuracy: 46.8629\n",
            "[2021-03-08 21:58:45,978 INFO] Model is improving ppl: 21.3276 --> 16.4002.\n",
            "[2021-03-08 21:58:45,978 INFO] Model is improving acc: 42.2414 --> 46.8629.\n",
            "[2021-03-08 21:58:57,996 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 21:59:01,716 INFO] Step 600/100000; acc:  47.45; ppl: 16.16; xent: 2.78; lr: 0.00100; 9591/10262 tok/s;    119 sec\n",
            "[2021-03-08 21:59:01,719 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:59:07,415 INFO] Validation perplexity: 13.1296\n",
            "[2021-03-08 21:59:07,415 INFO] Validation accuracy: 50.9575\n",
            "[2021-03-08 21:59:07,416 INFO] Model is improving ppl: 16.4002 --> 13.1296.\n",
            "[2021-03-08 21:59:07,416 INFO] Model is improving acc: 46.8629 --> 50.9575.\n",
            "[2021-03-08 21:59:22,576 INFO] Step 700/100000; acc:  51.07; ppl: 13.00; xent: 2.56; lr: 0.00100; 9553/10197 tok/s;    140 sec\n",
            "[2021-03-08 21:59:22,579 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:59:28,270 INFO] Validation perplexity: 10.9923\n",
            "[2021-03-08 21:59:28,270 INFO] Validation accuracy: 54.4249\n",
            "[2021-03-08 21:59:28,271 INFO] Model is improving ppl: 13.1296 --> 10.9923.\n",
            "[2021-03-08 21:59:28,271 INFO] Model is improving acc: 50.9575 --> 54.4249.\n",
            "[2021-03-08 21:59:43,108 INFO] Step 800/100000; acc:  53.93; ppl: 11.00; xent: 2.40; lr: 0.00100; 9674/10404 tok/s;    160 sec\n",
            "[2021-03-08 21:59:43,111 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 21:59:48,708 INFO] Validation perplexity: 9.61531\n",
            "[2021-03-08 21:59:48,708 INFO] Validation accuracy: 56.8117\n",
            "[2021-03-08 21:59:48,709 INFO] Model is improving ppl: 10.9923 --> 9.61531.\n",
            "[2021-03-08 21:59:48,709 INFO] Model is improving acc: 54.4249 --> 56.8117.\n",
            "[2021-03-08 21:59:58,582 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:00:03,996 INFO] Step 900/100000; acc:  55.85; ppl:  9.78; xent: 2.28; lr: 0.00100; 9512/10216 tok/s;    181 sec\n",
            "[2021-03-08 22:00:03,999 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:00:09,620 INFO] Validation perplexity: 8.69116\n",
            "[2021-03-08 22:00:09,620 INFO] Validation accuracy: 58.5719\n",
            "[2021-03-08 22:00:09,621 INFO] Model is improving ppl: 9.61531 --> 8.69116.\n",
            "[2021-03-08 22:00:09,621 INFO] Model is improving acc: 56.8117 --> 58.5719.\n",
            "[2021-03-08 22:00:24,740 INFO] Step 1000/100000; acc:  57.48; ppl:  8.76; xent: 2.17; lr: 0.00100; 9619/10265 tok/s;    202 sec\n",
            "[2021-03-08 22:00:24,742 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:00:30,247 INFO] Validation perplexity: 8.03405\n",
            "[2021-03-08 22:00:30,248 INFO] Validation accuracy: 59.8874\n",
            "[2021-03-08 22:00:30,248 INFO] Model is improving ppl: 8.69116 --> 8.03405.\n",
            "[2021-03-08 22:00:30,248 INFO] Model is improving acc: 58.5719 --> 59.8874.\n",
            "[2021-03-08 22:00:30,302 INFO] Saving checkpoint kjv2bbe/run/models/kjv2bbe_step_1000.pt\n",
            "[2021-03-08 22:00:46,841 INFO] Step 1100/100000; acc:  58.82; ppl:  8.04; xent: 2.08; lr: 0.00100; 9035/9722 tok/s;    224 sec\n",
            "[2021-03-08 22:00:46,848 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:00:52,322 INFO] Validation perplexity: 7.54532\n",
            "[2021-03-08 22:00:52,322 INFO] Validation accuracy: 60.8452\n",
            "[2021-03-08 22:00:52,323 INFO] Model is improving ppl: 8.03405 --> 7.54532.\n",
            "[2021-03-08 22:00:52,323 INFO] Model is improving acc: 59.8874 --> 60.8452.\n",
            "[2021-03-08 22:01:00,278 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:01:07,451 INFO] Step 1200/100000; acc:  59.65; ppl:  7.55; xent: 2.02; lr: 0.00100; 9707/10399 tok/s;    245 sec\n",
            "[2021-03-08 22:01:07,454 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:01:13,297 INFO] Validation perplexity: 7.18034\n",
            "[2021-03-08 22:01:13,298 INFO] Validation accuracy: 61.6461\n",
            "[2021-03-08 22:01:13,298 INFO] Model is improving ppl: 7.54532 --> 7.18034.\n",
            "[2021-03-08 22:01:13,298 INFO] Model is improving acc: 60.8452 --> 61.6461.\n",
            "[2021-03-08 22:01:28,376 INFO] Step 1300/100000; acc:  61.12; ppl:  6.93; xent: 1.94; lr: 0.00100; 9550/10196 tok/s;    265 sec\n",
            "[2021-03-08 22:01:28,379 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:01:34,242 INFO] Validation perplexity: 6.89541\n",
            "[2021-03-08 22:01:34,242 INFO] Validation accuracy: 62.3286\n",
            "[2021-03-08 22:01:34,243 INFO] Model is improving ppl: 7.18034 --> 6.89541.\n",
            "[2021-03-08 22:01:34,243 INFO] Model is improving acc: 61.6461 --> 62.3286.\n",
            "[2021-03-08 22:01:49,530 INFO] Step 1400/100000; acc:  61.60; ppl:  6.65; xent: 1.89; lr: 0.00100; 9635/10322 tok/s;    287 sec\n",
            "[2021-03-08 22:01:49,533 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:01:55,147 INFO] Validation perplexity: 6.6625\n",
            "[2021-03-08 22:01:55,147 INFO] Validation accuracy: 62.8613\n",
            "[2021-03-08 22:01:55,147 INFO] Model is improving ppl: 6.89541 --> 6.6625.\n",
            "[2021-03-08 22:01:55,148 INFO] Model is improving acc: 62.3286 --> 62.8613.\n",
            "[2021-03-08 22:02:01,407 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:02:10,664 INFO] Step 1500/100000; acc:  62.14; ppl:  6.38; xent: 1.85; lr: 0.00100; 9429/10117 tok/s;    308 sec\n",
            "[2021-03-08 22:02:10,667 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:02:16,360 INFO] Validation perplexity: 6.46935\n",
            "[2021-03-08 22:02:16,360 INFO] Validation accuracy: 63.333\n",
            "[2021-03-08 22:02:16,361 INFO] Model is improving ppl: 6.6625 --> 6.46935.\n",
            "[2021-03-08 22:02:16,361 INFO] Model is improving acc: 62.8613 --> 63.333.\n",
            "[2021-03-08 22:02:31,487 INFO] Step 1600/100000; acc:  63.33; ppl:  5.93; xent: 1.78; lr: 0.00100; 9583/10234 tok/s;    329 sec\n",
            "[2021-03-08 22:02:31,491 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:02:37,237 INFO] Validation perplexity: 6.31813\n",
            "[2021-03-08 22:02:37,238 INFO] Validation accuracy: 63.7392\n",
            "[2021-03-08 22:02:37,238 INFO] Model is improving ppl: 6.46935 --> 6.31813.\n",
            "[2021-03-08 22:02:37,238 INFO] Model is improving acc: 63.333 --> 63.7392.\n",
            "[2021-03-08 22:02:52,084 INFO] Step 1700/100000; acc:  63.76; ppl:  5.75; xent: 1.75; lr: 0.00100; 9597/10315 tok/s;    349 sec\n",
            "[2021-03-08 22:02:52,087 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:02:57,693 INFO] Validation perplexity: 6.18072\n",
            "[2021-03-08 22:02:57,693 INFO] Validation accuracy: 64.0198\n",
            "[2021-03-08 22:02:57,694 INFO] Model is improving ppl: 6.31813 --> 6.18072.\n",
            "[2021-03-08 22:02:57,694 INFO] Model is improving acc: 63.7392 --> 64.0198.\n",
            "[2021-03-08 22:03:02,215 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:03:12,892 INFO] Step 1800/100000; acc:  63.92; ppl:  5.64; xent: 1.73; lr: 0.00100; 9594/10300 tok/s;    370 sec\n",
            "[2021-03-08 22:03:12,895 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:03:18,484 INFO] Validation perplexity: 6.07134\n",
            "[2021-03-08 22:03:18,484 INFO] Validation accuracy: 64.3163\n",
            "[2021-03-08 22:03:18,484 INFO] Model is improving ppl: 6.18072 --> 6.07134.\n",
            "[2021-03-08 22:03:18,484 INFO] Model is improving acc: 64.0198 --> 64.3163.\n",
            "[2021-03-08 22:03:33,526 INFO] Step 1900/100000; acc:  65.00; ppl:  5.27; xent: 1.66; lr: 0.00100; 9728/10382 tok/s;    391 sec\n",
            "[2021-03-08 22:03:33,529 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:03:39,172 INFO] Validation perplexity: 5.97523\n",
            "[2021-03-08 22:03:39,172 INFO] Validation accuracy: 64.5787\n",
            "[2021-03-08 22:03:39,173 INFO] Model is improving ppl: 6.07134 --> 5.97523.\n",
            "[2021-03-08 22:03:39,173 INFO] Model is improving acc: 64.3163 --> 64.5787.\n",
            "[2021-03-08 22:03:54,316 INFO] Step 2000/100000; acc:  65.28; ppl:  5.16; xent: 1.64; lr: 0.00100; 9562/10272 tok/s;    411 sec\n",
            "[2021-03-08 22:03:54,319 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:04:00,071 INFO] Validation perplexity: 5.8915\n",
            "[2021-03-08 22:04:00,071 INFO] Validation accuracy: 64.8047\n",
            "[2021-03-08 22:04:00,072 INFO] Model is improving ppl: 5.97523 --> 5.8915.\n",
            "[2021-03-08 22:04:00,072 INFO] Model is improving acc: 64.5787 --> 64.8047.\n",
            "[2021-03-08 22:04:00,126 INFO] Saving checkpoint kjv2bbe/run/models/kjv2bbe_step_2000.pt\n",
            "[2021-03-08 22:04:08,595 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:04:16,528 INFO] Step 2100/100000; acc:  65.53; ppl:  5.07; xent: 1.62; lr: 0.00100; 8973/9622 tok/s;    434 sec\n",
            "[2021-03-08 22:04:16,531 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:04:22,176 INFO] Validation perplexity: 5.82531\n",
            "[2021-03-08 22:04:22,176 INFO] Validation accuracy: 64.9711\n",
            "[2021-03-08 22:04:22,177 INFO] Model is improving ppl: 5.8915 --> 5.82531.\n",
            "[2021-03-08 22:04:22,177 INFO] Model is improving acc: 64.8047 --> 64.9711.\n",
            "[2021-03-08 22:04:37,843 INFO] Step 2200/100000; acc:  66.31; ppl:  4.81; xent: 1.57; lr: 0.00100; 9650/10290 tok/s;    455 sec\n",
            "[2021-03-08 22:04:37,846 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:04:43,528 INFO] Validation perplexity: 5.7687\n",
            "[2021-03-08 22:04:43,528 INFO] Validation accuracy: 65.1811\n",
            "[2021-03-08 22:04:43,528 INFO] Model is improving ppl: 5.82531 --> 5.7687.\n",
            "[2021-03-08 22:04:43,529 INFO] Model is improving acc: 64.9711 --> 65.1811.\n",
            "[2021-03-08 22:04:58,536 INFO] Step 2300/100000; acc:  66.41; ppl:  4.78; xent: 1.56; lr: 0.00100; 9563/10266 tok/s;    476 sec\n",
            "[2021-03-08 22:04:58,539 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:05:04,110 INFO] Validation perplexity: 5.71287\n",
            "[2021-03-08 22:05:04,110 INFO] Validation accuracy: 65.373\n",
            "[2021-03-08 22:05:04,111 INFO] Model is improving ppl: 5.7687 --> 5.71287.\n",
            "[2021-03-08 22:05:04,111 INFO] Model is improving acc: 65.1811 --> 65.373.\n",
            "[2021-03-08 22:05:09,632 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:05:18,999 INFO] Step 2400/100000; acc:  66.92; ppl:  4.64; xent: 1.53; lr: 0.00100; 9707/10416 tok/s;    496 sec\n",
            "[2021-03-08 22:05:19,002 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:05:24,543 INFO] Validation perplexity: 5.66652\n",
            "[2021-03-08 22:05:24,543 INFO] Validation accuracy: 65.4675\n",
            "[2021-03-08 22:05:24,544 INFO] Model is improving ppl: 5.71287 --> 5.66652.\n",
            "[2021-03-08 22:05:24,544 INFO] Model is improving acc: 65.373 --> 65.4675.\n",
            "[2021-03-08 22:05:40,040 INFO] Step 2500/100000; acc:  67.47; ppl:  4.46; xent: 1.49; lr: 0.00100; 9514/10172 tok/s;    517 sec\n",
            "[2021-03-08 22:05:40,043 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:05:45,720 INFO] Validation perplexity: 5.62851\n",
            "[2021-03-08 22:05:45,720 INFO] Validation accuracy: 65.6056\n",
            "[2021-03-08 22:05:45,720 INFO] Model is improving ppl: 5.66652 --> 5.62851.\n",
            "[2021-03-08 22:05:45,721 INFO] Model is improving acc: 65.4675 --> 65.6056.\n",
            "[2021-03-08 22:06:01,002 INFO] Step 2600/100000; acc:  67.57; ppl:  4.40; xent: 1.48; lr: 0.00100; 9448/10154 tok/s;    538 sec\n",
            "[2021-03-08 22:06:01,005 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:06:06,842 INFO] Validation perplexity: 5.59443\n",
            "[2021-03-08 22:06:06,842 INFO] Validation accuracy: 65.7386\n",
            "[2021-03-08 22:06:06,843 INFO] Model is improving ppl: 5.62851 --> 5.59443.\n",
            "[2021-03-08 22:06:06,843 INFO] Model is improving acc: 65.6056 --> 65.7386.\n",
            "[2021-03-08 22:06:10,527 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:06:21,896 INFO] Step 2700/100000; acc:  67.96; ppl:  4.30; xent: 1.46; lr: 0.00100; 9539/10237 tok/s;    559 sec\n",
            "[2021-03-08 22:06:21,899 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:06:27,613 INFO] Validation perplexity: 5.56361\n",
            "[2021-03-08 22:06:27,613 INFO] Validation accuracy: 65.873\n",
            "[2021-03-08 22:06:27,613 INFO] Model is improving ppl: 5.59443 --> 5.56361.\n",
            "[2021-03-08 22:06:27,614 INFO] Model is improving acc: 65.7386 --> 65.873.\n",
            "[2021-03-08 22:06:42,387 INFO] Step 2800/100000; acc:  68.48; ppl:  4.18; xent: 1.43; lr: 0.00100; 9843/10502 tok/s;    579 sec\n",
            "[2021-03-08 22:06:42,390 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:06:48,138 INFO] Validation perplexity: 5.5433\n",
            "[2021-03-08 22:06:48,138 INFO] Validation accuracy: 65.9959\n",
            "[2021-03-08 22:06:48,139 INFO] Model is improving ppl: 5.56361 --> 5.5433.\n",
            "[2021-03-08 22:06:48,139 INFO] Model is improving acc: 65.873 --> 65.9959.\n",
            "[2021-03-08 22:07:03,115 INFO] Step 2900/100000; acc:  68.64; ppl:  4.12; xent: 1.42; lr: 0.00100; 9569/10272 tok/s;    600 sec\n",
            "[2021-03-08 22:07:03,118 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:07:08,850 INFO] Validation perplexity: 5.51931\n",
            "[2021-03-08 22:07:08,850 INFO] Validation accuracy: 66.0867\n",
            "[2021-03-08 22:07:08,851 INFO] Model is improving ppl: 5.5433 --> 5.51931.\n",
            "[2021-03-08 22:07:08,851 INFO] Model is improving acc: 65.9959 --> 66.0867.\n",
            "[2021-03-08 22:07:10,952 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:07:24,367 INFO] Step 3000/100000; acc:  68.95; ppl:  4.06; xent: 1.40; lr: 0.00100; 9602/10269 tok/s;    621 sec\n",
            "[2021-03-08 22:07:24,370 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:07:29,957 INFO] Validation perplexity: 5.50348\n",
            "[2021-03-08 22:07:29,958 INFO] Validation accuracy: 66.1587\n",
            "[2021-03-08 22:07:29,958 INFO] Model is improving ppl: 5.51931 --> 5.50348.\n",
            "[2021-03-08 22:07:29,958 INFO] Model is improving acc: 66.0867 --> 66.1587.\n",
            "[2021-03-08 22:07:30,010 INFO] Saving checkpoint kjv2bbe/run/models/kjv2bbe_step_3000.pt\n",
            "[2021-03-08 22:07:46,463 INFO] Step 3100/100000; acc:  69.67; ppl:  3.91; xent: 1.36; lr: 0.00100; 9078/9716 tok/s;    644 sec\n",
            "[2021-03-08 22:07:46,466 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:07:52,276 INFO] Validation perplexity: 5.49162\n",
            "[2021-03-08 22:07:52,276 INFO] Validation accuracy: 66.2175\n",
            "[2021-03-08 22:07:52,276 INFO] Model is improving ppl: 5.50348 --> 5.49162.\n",
            "[2021-03-08 22:07:52,277 INFO] Model is improving acc: 66.1587 --> 66.2175.\n",
            "[2021-03-08 22:08:07,305 INFO] Step 3200/100000; acc:  69.35; ppl:  3.92; xent: 1.37; lr: 0.00100; 9491/10196 tok/s;    664 sec\n",
            "[2021-03-08 22:08:07,308 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:08:13,293 INFO] Validation perplexity: 5.47905\n",
            "[2021-03-08 22:08:13,293 INFO] Validation accuracy: 66.2669\n",
            "[2021-03-08 22:08:13,294 INFO] Model is improving ppl: 5.49162 --> 5.47905.\n",
            "[2021-03-08 22:08:13,294 INFO] Model is improving acc: 66.2175 --> 66.2669.\n",
            "[2021-03-08 22:08:13,318 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:08:28,330 INFO] Step 3300/100000; acc:  70.08; ppl:  3.79; xent: 1.33; lr: 0.00100; 9429/10102 tok/s;    685 sec\n",
            "[2021-03-08 22:08:28,333 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:08:34,323 INFO] Validation perplexity: 5.46905\n",
            "[2021-03-08 22:08:34,323 INFO] Validation accuracy: 66.3556\n",
            "[2021-03-08 22:08:34,324 INFO] Model is improving ppl: 5.47905 --> 5.46905.\n",
            "[2021-03-08 22:08:34,324 INFO] Model is improving acc: 66.2669 --> 66.3556.\n",
            "[2021-03-08 22:08:55,389 INFO] Validation perplexity: 5.46872\n",
            "[2021-03-08 22:08:55,389 INFO] Validation accuracy: 66.437\n",
            "[2021-03-08 22:08:55,390 INFO] Model is improving ppl: 5.46905 --> 5.46872.\n",
            "[2021-03-08 22:08:55,390 INFO] Model is improving acc: 66.3556 --> 66.437.\n",
            "[2021-03-08 22:09:09,182 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:09:10,906 INFO] Step 3500/100000; acc:  70.37; ppl:  3.71; xent: 1.31; lr: 0.00100; 9233/9919 tok/s;    728 sec\n",
            "[2021-03-08 22:09:10,909 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:09:16,444 INFO] Validation perplexity: 5.46448\n",
            "[2021-03-08 22:09:16,444 INFO] Validation accuracy: 66.453\n",
            "[2021-03-08 22:09:16,444 INFO] Model is improving ppl: 5.46872 --> 5.46448.\n",
            "[2021-03-08 22:09:16,444 INFO] Model is improving acc: 66.437 --> 66.453.\n",
            "[2021-03-08 22:09:37,004 INFO] Validation perplexity: 5.46243\n",
            "[2021-03-08 22:09:37,004 INFO] Validation accuracy: 66.5228\n",
            "[2021-03-08 22:09:37,004 INFO] Model is improving ppl: 5.46448 --> 5.46243.\n",
            "[2021-03-08 22:09:37,005 INFO] Model is improving acc: 66.453 --> 66.5228.\n",
            "[2021-03-08 22:09:51,988 INFO] Step 3700/100000; acc:  71.41; ppl:  3.51; xent: 1.25; lr: 0.00100; 9707/10405 tok/s;    769 sec\n",
            "[2021-03-08 22:09:51,992 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:10:12,975 INFO] Step 3800/100000; acc:  71.04; ppl:  3.55; xent: 1.27; lr: 0.00100; 9704/10391 tok/s;    790 sec\n",
            "[2021-03-08 22:10:12,978 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:10:18,726 INFO] Validation perplexity: 5.46405\n",
            "[2021-03-08 22:10:18,726 INFO] Validation accuracy: 66.626\n",
            "[2021-03-08 22:10:18,726 INFO] Stalled patience: 8/10\n",
            "[2021-03-08 22:10:19,952 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:10:33,948 INFO] Step 3900/100000; acc:  71.49; ppl:  3.44; xent: 1.24; lr: 0.00100; 9513/10168 tok/s;    811 sec\n",
            "[2021-03-08 22:10:33,950 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:10:39,754 INFO] Validation perplexity: 5.46744\n",
            "[2021-03-08 22:10:39,754 INFO] Validation accuracy: 66.6885\n",
            "[2021-03-08 22:10:39,755 INFO] Stalled patience: 7/10\n",
            "[2021-03-08 22:10:55,044 INFO] Step 4000/100000; acc:  72.20; ppl:  3.35; xent: 1.21; lr: 0.00100; 9444/10143 tok/s;    832 sec\n",
            "[2021-03-08 22:10:55,047 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:11:00,948 INFO] Validation perplexity: 5.47143\n",
            "[2021-03-08 22:11:00,949 INFO] Validation accuracy: 66.7517\n",
            "[2021-03-08 22:11:00,949 INFO] Stalled patience: 6/10\n",
            "[2021-03-08 22:11:01,003 INFO] Saving checkpoint kjv2bbe/run/models/kjv2bbe_step_4000.pt\n",
            "[2021-03-08 22:11:17,616 INFO] Step 4100/100000; acc:  71.85; ppl:  3.38; xent: 1.22; lr: 0.00100; 8760/9400 tok/s;    855 sec\n",
            "[2021-03-08 22:11:17,619 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:11:23,193 INFO] Validation perplexity: 5.47597\n",
            "[2021-03-08 22:11:23,193 INFO] Validation accuracy: 66.7837\n",
            "[2021-03-08 22:11:23,194 INFO] Stalled patience: 5/10\n",
            "[2021-03-08 22:11:44,205 INFO] Validation perplexity: 5.48226\n",
            "[2021-03-08 22:11:44,205 INFO] Validation accuracy: 66.8331\n",
            "[2021-03-08 22:11:44,205 INFO] Stalled patience: 4/10\n",
            "[2021-03-08 22:11:58,798 INFO] Step 4300/100000; acc:  72.79; ppl:  3.23; xent: 1.17; lr: 0.00100; 9826/10545 tok/s;    896 sec\n",
            "[2021-03-08 22:11:58,801 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:12:04,583 INFO] Validation perplexity: 5.49464\n",
            "[2021-03-08 22:12:04,584 INFO] Validation accuracy: 66.8832\n",
            "[2021-03-08 22:12:04,584 INFO] Stalled patience: 3/10\n",
            "[2021-03-08 22:12:17,267 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.bbe, align=None)...\n",
            "[2021-03-08 22:12:19,563 INFO] Step 4400/100000; acc:  72.62; ppl:  3.22; xent: 1.17; lr: 0.00100; 9619/10315 tok/s;    917 sec\n",
            "[2021-03-08 22:12:19,566 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:12:25,287 INFO] Validation perplexity: 5.50396\n",
            "[2021-03-08 22:12:25,287 INFO] Validation accuracy: 66.8607\n",
            "[2021-03-08 22:12:25,288 INFO] Stalled patience: 2/10\n",
            "[2021-03-08 22:12:40,420 INFO] Step 4500/100000; acc:  73.10; ppl:  3.15; xent: 1.15; lr: 0.00100; 9539/10182 tok/s;    937 sec\n",
            "[2021-03-08 22:12:40,423 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:13:01,576 INFO] Step 4600/100000; acc:  73.26; ppl:  3.13; xent: 1.14; lr: 0.00100; 9687/10372 tok/s;    959 sec\n",
            "[2021-03-08 22:13:01,580 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.bbe, align=None)...\n",
            "[2021-03-08 22:13:07,368 INFO] Validation perplexity: 5.53169\n",
            "[2021-03-08 22:13:07,368 INFO] Validation accuracy: 66.8927\n",
            "[2021-03-08 22:13:07,369 INFO] Stalled patience: 0/10\n",
            "[2021-03-08 22:13:07,369 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2021-03-08 22:13:07,369 INFO] Best model found at step 3600\n",
            "[2021-03-08 22:13:07,424 INFO] Saving checkpoint kjv2bbe/run/models/kjv2bbe_step_4600.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhbd32tKY6ca"
      },
      "source": [
        "# retrieve the models\r\n",
        "kjv2bbe_models = [ KJV2BBE_MODEL_PATH / f for f in listdir(KJV2BBE_MODEL_PATH) if f.startswith(KJV2BBE_MODEL_PREFIX)]\r\n",
        "\r\n",
        "KJV2BBE_PREDICTIONS_PATH = KJV2BBE_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{KJV2BBE_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']\r\n",
        "\r\n",
        "kjv2bbe_scores = evaluate(kjv2bbe_models, \r\n",
        "                          kjv2bbe_file_paths['test'][0], \r\n",
        "                          kjv2bbe_file_paths['test'][1], \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          str(KJV2BBE_PREDICTIONS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAtSw5N8DpE"
      },
      "source": [
        "The best performing model is after 3100 training iterations with early stopping and beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 35.8819\r\n",
        "    METEOR = 0.5453"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl4ZN87d-Jex"
      },
      "source": [
        "#### User Studies Predictions\r\n",
        "\r\n",
        "Generate predictions for the user studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a-CXJdbyCJ1"
      },
      "source": [
        "queries = ['In the beginning God created the heaven and the earth.', \r\n",
        "           \"And Adam called his wife's name Eve; because she was the mother of all living.\", \r\n",
        "           'And the LORD God called unto Adam, and said unto him, Where art thou?', \r\n",
        "           'And God remembered Noah, and every living thing, and all the cattle that was with him in the ark: and God made a wind to pass over the earth, and the waters assuaged;', \r\n",
        "           'And God looked upon the earth, and, behold, it was corrupt; for all flesh had corrupted his way upon the earth.', \r\n",
        "           'There went in two and two unto Noah into the ark, the male and the female, as God had commanded Noah.', \r\n",
        "           'And the waters decreased continually until the tenth month: in the tenth month, on the first day of the month, were the tops of the mountains seen.', \r\n",
        "           'And on the seventh day God ended his work which he had made; and he rested on the seventh day from all his work which he had made.', \r\n",
        "           'And the earth brought forth grass, and herb yielding seed after his kind, and the tree yielding fruit, whose seed was in itself, after his kind: and God saw that it was good.', \r\n",
        "           'And God did so that night: for it was dry upon the fleece only, and there was dew on all the ground.', \r\n",
        "           'Then said the trees unto the vine, Come thou, and reign over us.', \r\n",
        "           'Wherefore I have not sinned against thee, but thou doest me wrong to war against me: the LORD the Judge be judge this day between the children of Israel and the children of Ammon.', \r\n",
        "           'The labour of the foolish wearieth every one of them, because he knoweth not how to go to the city.', \r\n",
        "           'And if he trespass against thee seven times in a day, and seven times in a day turn again to thee, saying, I repent; thou shalt forgive him.',\r\n",
        "           'You only have I known of all the families of the earth: therefore I will punish you for all your iniquities.', \r\n",
        "           'And he is the head of the body, the church: who is the beginning, the firstborn from the dead; that in all things he might have the preeminence.', \r\n",
        "           'And the four beasts said, Amen. And the four and twenty elders fell down and worshipped him that liveth for ever and ever.', \r\n",
        "           'He hath also broken my teeth with gravel stones, he hath covered me with ashes.', \r\n",
        "           'If Satan also be divided against himself, how shall his kingdom stand? because ye say that I cast out devils through Beelzebub.', \r\n",
        "           'For men shall be lovers of their own selves, covetous, boasters, proud, blasphemers, disobedient to parents, unthankful, unholy,', \r\n",
        "           'And God said, Let there be lights in the firmament of the heaven to divide the day from the night; and let them be for signs, and for seasons, and for days, and years:', \r\n",
        "           'And Isaac trembled very exceedingly, and said, Who? where is he that hath taken venison, and brought it me, and I have eaten of all before thou camest, and have blessed him? yea, and he shall be blessed.', \r\n",
        "           'And the angel of the LORD called unto him out of heaven, and said, Abraham, Abraham: and he said, Here am I.', \r\n",
        "           'Thus they made a covenant at Beersheba: then Abimelech rose up, and Phichol the chief captain of his host, and they returned into the land of the Philistines.', \r\n",
        "           'And Abraham stretched forth his hand, and took the knife to slay his son.', \r\n",
        "           'So Abraham returned unto his young men, and they rose up and went together to Beersheba; and Abraham dwelt at Beersheba.', \r\n",
        "           'And you, being dead in your sins and the uncircumcision of your flesh, hath he quickened together with him, having forgiven you all trespasses;', \r\n",
        "           'Wives, submit yourselves unto your own husbands, as it is fit in the Lord.', \r\n",
        "           'But he that doeth wrong shall receive for the wrong which he hath done: and there is no respect of persons.', \r\n",
        "           \"Aristarchus my fellowprisoner saluteth you, and Marcus, sister's son to Barnabas, (touching whom ye received commandments: if he come unto you, receive him;)\", \r\n",
        "           'Now unto God and our Father be glory for ever and ever. Amen.'\r\n",
        "           ]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3EFlddk9KXl"
      },
      "source": [
        "model = KJV2BBE_MODEL_PATH / f'{KJV2BBE_MODEL_PREFIX}_step_4600.pt'\r\n",
        "BBE_TEST_TOK = DATA_PATH / 'user-studies.eng'\r\n",
        "BBE_TEST_PRED = KJV2BBE_PREDICTIONS_PATH / 'bbe-text-pred.txt'\r\n",
        "\r\n",
        "with open(BBE_TEST_TOK, mode='w+', encoding='utf-8') as f:\r\n",
        "      eval_text = [l.rstrip('\\n') for l in f]\r\n",
        "      f.write('\\n'.join([\" \".join(tokenizer(l, 'enm', **token_kwargs)) for l in queries]))\r\n",
        "\r\n",
        "!onmt_translate -model \"{model}\" -src \"{BBE_TEST_TOK}\" -output \"{BBE_TEST_PRED}\" -min_length 1 -max_length \"{MAX_SENTENCE_LENGTH}\" -beam_size 5 -gpu 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPNRubW9RST"
      },
      "source": [
        "tokenize = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "hypotheses = get_detokenized_file(BBE_TEST_PRED, tokenize)\r\n",
        "\r\n",
        "for hyp in hypotheses:\r\n",
        "    print(hyp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_x7_8W1-Dj6"
      },
      "source": [
        "### BBE to KJV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9eCtafP-Ro8"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "BBE2KJV_TRANSLATE_NAME = 'bbe2kjv'\r\n",
        "!mkdir -p '{BBE2KJV_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "BBE2KJV_TRANSLATE_PATH = Path(BBE2KJV_TRANSLATE_NAME)\r\n",
        "BBE2KJV_RUN_PATH = BBE2KJV_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{BBE2KJV_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables\r\n",
        "BBE2KJV_SOURCE_VER = 't_bbe'\r\n",
        "BBE2KJV_SRC_LANG_CODE = 'eng'\r\n",
        "BBE2KJV_TARGET_VER = 't_kjv'\r\n",
        "BBE2KJV_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV_phJ5x-qUh"
      },
      "source": [
        "BBE2KJV_SRC_EXT = BBE2KJV_SOURCE_VER[2:]\r\n",
        "BBE2KJV_TGT_EXT = BBE2KJV_TARGET_VER[2:]\r\n",
        "\r\n",
        "bbe2kjv_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{BBE2KJV_SRC_EXT}', DATA_PATH / f'bible-train.{BBE2KJV_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{BBE2KJV_SRC_EXT}', DATA_PATH / f'bible-valid.{BBE2KJV_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{BBE2KJV_SRC_EXT}', DATA_PATH / f'bible-test.{BBE2KJV_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULDwKpdq-4pJ"
      },
      "source": [
        "BBE2KJV_SRC_VOCAB_PATH = BBE2KJV_RUN_PATH / 'vocab.src'\r\n",
        "BBE2KJV_TGT_VOCAB_PATH = BBE2KJV_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "bbe2kjv_yaml = 'bbe2kjv.yaml'\r\n",
        "\r\n",
        "BBE2KJV_MODEL_PATH = BBE2KJV_RUN_PATH / 'models'\r\n",
        "BBE2KJV_MODEL_PREFIX = 'bbe2kjv'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeJ8tSGO_D7j"
      },
      "source": [
        "config =  f'''# {bbe2kjv_yaml}\r\n",
        "save_data: {BBE2KJV_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {BBE2KJV_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {BBE2KJV_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    corpus_1:\r\n",
        "        path_src: {bbe2kjv_file_paths['training'][0]}\r\n",
        "        path_tgt: {bbe2kjv_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {bbe2kjv_file_paths['validation'][0]}\r\n",
        "        path_tgt: {bbe2kjv_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {BBE2KJV_MODEL_PATH / BBE2KJV_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "# early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {BBE2KJV_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "bidir_edges: True\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 256\r\n",
        "dropout: 0.5\r\n",
        "attn_dropout: 0.3\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / bbe2kjv_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na-rD7WT_Pxd"
      },
      "source": [
        "build_and_train(CONFIG_PATH / bbe2kjv_yaml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KES6Qf1L_Svq"
      },
      "source": [
        "# retrieve the models\r\n",
        "bbe2kjv_models = [ BBE2KJV_MODEL_PATH / f for f in listdir(BBE2KJV_MODEL_PATH) if f.startswith(BBE2KJV_MODEL_PREFIX)]\r\n",
        "\r\n",
        "BBE2KJV_PREDICTIONS_PATH = BBE2KJV_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{BBE2KJV_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "eval_metrics = ['sacrebleu', 'meteor']\r\n",
        "\r\n",
        "bbe2kjv_scores = evaluate(bbe2kjv_models, \r\n",
        "                          bbe2kjv_file_paths['test'][0], \r\n",
        "                          bbe2kjv_file_paths['test'][1], \r\n",
        "                          eval_metrics,\r\n",
        "                          token_kwargs,\r\n",
        "                          MAX_SENTENCE_LENGTH, \r\n",
        "                          5, \r\n",
        "                          str(BBE2KJV_PREDICTIONS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7FPLnCyENjb"
      },
      "source": [
        "The best performing model is after 4600 training iterations with early stopping and beam size 5:\r\n",
        "\r\n",
        "    BLEU   = 30.9229\r\n",
        "    METEOR = 0.4931"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVRlyBymEyTg"
      },
      "source": [
        "#### User Studies Predictions\r\n",
        "\r\n",
        "Generate predictions for the user studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcgrCJeEDcKq"
      },
      "source": [
        "queries = ['At the first God made the heaven and the earth', \r\n",
        "           'And the man gave his wife the name of Eve because she was the mother of all who have life.', \r\n",
        "           'And the voice of the Lord God came to the man, saying, Where are you?', \r\n",
        "           'And God kept Noah in mind, and all the living things and the cattle which were with him in the ark: and God sent a wind over the earth, and the waters went down.', \r\n",
        "           'And God, looking on the earth, saw that it was evil: for the way of all flesh had become evil on the earth.', \r\n",
        "           'In twos, male and female, they went into the ark with Noah, as God had said.', \r\n",
        "           'And still the waters went on falling, till on the first day of the tenth month the tops of the mountains were seen.', \r\n",
        "           'And on the seventh day God came to the end of all his work; and on the seventh day he took his rest from all the work which he had done.', \r\n",
        "           'And grass came up on the earth, and every plant producing seed of its sort, and every tree producing fruit, in which is its seed, of its sort: and God saw that it was good.', \r\n",
        "           'And that night God did so; for the wool was dry, and there was dew on all the earth round it.', \r\n",
        "           'Then the trees said to the vine, You come and be king over us.', \r\n",
        "           'So I have done no wrong against you, but you are doing wrong to me in fighting against me: may the Lord, who is Judge this day, be judge between the children of Israel and the children of Ammon.', \r\n",
        "           'The work of the foolish will be a weariness to him, because he has no knowledge of the way to the town.', \r\n",
        "           'And if he does you wrong seven times in a day, and seven times comes to you and says, I have regret for what I have done; let him have forgiveness.', \r\n",
        "           'You only of all the families of the earth have I taken care of: for this reason I will send punishment on you for all your sins.', \r\n",
        "           'And he is the head of the body, the church: the starting point of all things, the first to come again from the dead; so that in all things he might have the chief place.', \r\n",
        "           'And the four beasts said, So be it. And the rulers went down on their faces and gave worship.', \r\n",
        "           'By him my teeth have been broken with crushed stones, and I am bent low in the dust.', \r\n",
        "           'If, then, Satan is at war with himself, how will he keep his kingdom? because you say that I send evil spirits out of men by the help of Beelzebul.', \r\n",
        "           'For men will be lovers of self, lovers of money, uplifted in pride, given to bitter words, going against the authority of their fathers, never giving praise, having no religion,', \r\n",
        "           'And God said, Let there be lights in the arch of heaven, for a division between the day and the night, and let them be for signs, and for marking the changes of the year, and for days and for years:', \r\n",
        "           'And in great fear Isaac said, Who then is he who got meat and put it before me, and I took it all before you came, and gave him a blessing, and his it will be?', \r\n",
        "           'But the voice of the angel of the Lord came from heaven, saying, Abraham, Abraham: and he said, Here am I.', \r\n",
        "           'So they made an agreement at Beer-sheba, and Abimelech and Phicol, the captain of his army, went back to the land of the Philistines.', \r\n",
        "           'And stretching out his hand, Abraham took the knife to put his son to death.', \r\n",
        "           'Then Abraham went back to his young men and they went together to Beer-sheba, the place where Abraham was living.', \r\n",
        "           'And you, being dead through your sins and the evil condition of your flesh, to you, I say, he gave life together with him, and forgiveness of all our sins;', \r\n",
        "           'Wives, be under the authority of your husbands, as is right in the Lord.', \r\n",
        "           \"For the wrongdoer will have punishment for the wrong he has done, without respect for any man's position.\", \r\n",
        "           'Aristarchus, my brother-prisoner, sends his love to you, and Mark, a relation of Barnabas (about whom you have been given orders: if he comes to you, be kind to him),', \r\n",
        "           'Now to God our Father be glory for ever and ever. So be it.'\r\n",
        "           ]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TGmfXY3E1Ei"
      },
      "source": [
        "model = BBE2KJV_MODEL_PATH / f'{BBE2KJV_MODEL_PREFIX}_step_4600.pt'\r\n",
        "KJV_TEST_TOK = DATA_PATH / 'user-studies.kjv'\r\n",
        "KJV_TEST_PRED = BBE2KJV_PREDICTIONS_PATH / 'kjv-text-pred.txt'\r\n",
        "\r\n",
        "with open(KJV_TEST_TOK, mode='w+', encoding='utf-8') as f:\r\n",
        "      eval_text = [l.rstrip('\\n') for l in f]\r\n",
        "      f.write('\\n'.join([\" \".join(tokenizer(l, 'enm', **token_kwargs)) for l in queries]))\r\n",
        "\r\n",
        "!onmt_translate -model \"{model}\" -src \"{KJV_TEST_TOK}\" -output \"{KJV_TEST_PRED}\" -min_length 1 -max_length \"{MAX_SENTENCE_LENGTH}\" -beam_size 5 -gpu 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGVeL1p5E3Yl"
      },
      "source": [
        "tokenize = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "hypotheses = get_detokenized_file(KJV_TEST_PRED, tokenize)\r\n",
        "\r\n",
        "for hyp in hypotheses:\r\n",
        "    print(hyp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}