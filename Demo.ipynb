{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ã†lfric to Albert Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take a few minutes\n",
    "!pip install texttable > /dev/null\n",
    "!pip install contractions > /dev/null\n",
    "!pip install git+https://github.com/huggingface/transformers.git@master > /dev/null\n",
    "!pip install git+https://github.com/huggingface/datasets.git@master > /dev/null\n",
    "!pip install sentencepiece > /dev/null\n",
    "!pip install cltk==0.1.121 > /dev/null\n",
    "!pip install nltk==3.5 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the big limitations of our project was the limited corpus size. The bible corpus contains only around 30k verses, split between the Old and New Testaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarize_data import *\n",
    "print_testament_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different books for the Bible can vary stylistically. They may be written in vastly different time periods, perspectives, and genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_genre_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accurate testing, it was important for us to get a roughly even spread of the different bible genres for our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_genre_data_split_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Modern and Middle English Bible versions may differ slightly in the exact verses provided, but are largely similar. On the other hand, the two Old English Bible versions we used, Aelfric's Old Testament and the West-Saxon Gospels, only contain a small subset of the total Bible books, let alone verses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_testament_table('t_alf')\n",
    "print()\n",
    "print_testament_table('t_wsg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these two versions vary drastically, we combined their verses in order to use as much data as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_genre_table('t_alf_wsg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, different Bible versions can differ in which verses and books they contain. In order to train any sequence-to-sequence model, we first need to pair together all the Bible verses shared by the different relevant Bible versions. To do this, we use our `create_datasets` function. This function is our is our swiss army knife for data preprocessing. It does the following:\n",
    "\n",
    " - Pairs all Bible verses shared between the given Bible versions\n",
    " - Runs any number of specified text pre-processing operations\n",
    " - Sets aside the verses from pre-defined test books into a test set\n",
    " - Splits the remaining verses into training and validation sets depending on the requested training split\n",
    " - Saves the datasets to files if requested\n",
    " - Shuffles the datasets if requested\n",
    " - Returns the datasets in an easy-to-use dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_manager import *\n",
    "versions = get_bible_versions_by_file_name(['t_kjv', 't_bbe'])\n",
    "datasets = create_datasets(\n",
    "    bible_versions = versions,\n",
    "    training_fraction = 0.85,\n",
    "    preprocess_operations = [\n",
    "        preprocess_expand_contractions(),\n",
    "        preprocess_filter_num_words(max_num_words = 35, min_num_words = 4),\n",
    "        preprocess_filter_num_sentences(max_num_sentences = 1),\n",
    "        preprocess_remove_punctuation(preserve_periods = True),\n",
    "        preprocess_lowercase()\n",
    "    ],\n",
    "    write_files = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['test']['t_kjv'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any pre-process operations, the results would contain much more content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = create_datasets(\n",
    "    bible_versions = versions,\n",
    "    training_fraction = 0.85,\n",
    "    write_files = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['test']['t_kjv'][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By saving the split datasets to files, the same data can be used for consistent results and repreducability. The data can be loaded quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l data/split/*\n",
    "print()\n",
    "datasets = load_datasets()\n",
    "datasets['test']['t_kjv'][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from transformers import (\n",
    "    BartForConditionalGeneration, BartTokenizer\n",
    ")\n",
    "\n",
    "# Model path\n",
    "from os.path import join\n",
    "model_path = join('models', 'bart-bbe-to-kjv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load one of our fine-tuned sequence-to-sequence transformer models along with a pre-trained tokenizer (this might take a minute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(model_path, max_length = 100)\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a transformer pipeline for translating text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline('translation_bbe_to_kjv', model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can translate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_verses = 4\n",
    "source_verses, target_verses = datasets['test']['t_bbe'][:num_verses], datasets['test']['t_kjv'][:num_verses]\n",
    "predicted_verses = [translation['translation_text'] for translation in translator(source_verses, return_text = True)]\n",
    "\n",
    "for (source_verse, target_verse, predicted_verse) in zip(source_verses, target_verses, predicted_verses):\n",
    "    print(f'SOURCE:    {source_verse}')\n",
    "    print(f'TARGET:    {target_verse}')\n",
    "    print(f'PREDICTED: {predicted_verse}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best of all, you can make your own predictions (feel free to pass whatever you want to the translate function below!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text: str) -> str:\n",
    "    # translates a single string\n",
    "    return translator(text, return_text = True)[0]['translation_text']\n",
    "\n",
    "translate('And the fearless instructors gave us a good grade in the class. For just they were. And full of kindness in their soul.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notable findings (Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to skip this section if you're not interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer seems to have learned parallelism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate('For they were just.'))\n",
    "print(translate('For they were just. And full of kindness in their soul.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the second sentence was extrapolated into the first sentence, shown by how the first sentence was translated differently when followed by the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model learned that 'lord' is often capitalized in the King James Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('What did the lord say to you?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model may translate a sentence differently depending on the ending puncutation (compare word order with above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('What did the lord say to you.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still learned to be derogatory towards homosexuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('He was a homosexual man.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was, after all, trained from verses such as:\n",
    "`There shall be no prostitute of the daughters of Israel, neither shall there be a sodomite of the sons of Israel.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as opposed to our previous models, it seems like these later models with more training and slightly different methods were less biased against homosexuals and less prone to complete failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('He was a gay man.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously: `He was a man of the offspring of the evil spirits;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('The black man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously: `The black man, the king of the army, the captain of the army, the captains of the army, the captains of the captains of the captains...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there was still gender bias, assuming that pretty much any profession is held by men, except those associated with women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate('The person had a marriage.'))\n",
    "print()\n",
    "print(translate('The carpenter had a marriage.'))\n",
    "print(translate('The tailor had a marriage.'))\n",
    "print(translate('The butcher had a marriage.'))\n",
    "print(translate('The blacksmith had a marriage.'))\n",
    "print(translate('The real estate agent had a marriage.'))\n",
    "print(translate('The journalist had a marriage.'))\n",
    "print(translate('The artist had a marriage.'))\n",
    "# etc., there are many more\n",
    "print()\n",
    "print(translate('The nurse had a marriage.'))\n",
    "print(translate('The babysitter had a marriage.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We received inconclusive results when trying to determine whether the gender bias was inherent to the models or if it was learned. More humerously, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('The avocado had a marriage.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model understands context, and translates the same word differently even within the same sentence (loving -> loving and loving -> loveth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"Now I'm saving all my loving for someone who's loving me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, some quotes by Yoda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('Once you start down the dark path, forever will it dominate your destiny. Consume you, it will.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('Death is a natural part of life. Rejoice for those around you who transform into the Force. Mourn them do not. Miss them do not. Attachment leads to jealously.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('On many long journeys have I gone. And waited, too, for others to return from journeys of their own. Some return; some are broken; some come back so different only their names remain.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('No longer certain, that one ever does win a war, I am. For in fighting the battles, the bloodshed, already lost we have. Yet, open to us a path remains. That unknown to the Sith is. Through this path, victory we may yet find. Not victory in the Clone Wars, but victory for all time.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('I canâ€™t believe it, said Luke Skywalker. And Yoda replied, That is why you fail.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
