{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OpenNMT-Middle & Modern.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "11CHwrqLnOYq7kakfXe-XpdM66I-yWdHi",
      "authorship_tag": "ABX9TyPf3E78BI+8oJsttmg42QSP"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7QLIgUmO4gf"
      },
      "source": [
        "# OpenNMT-py Middle & Modern\r\n",
        "\r\n",
        "Sequence-to-Sequence Encoder-Decoder Models for translating Middle and Modern English\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRUvKr9nywe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42619c3e-6722-4001-ae86-b30066f2c510"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "# default location for the drive\r\n",
        "ROOT = \"/content/gdrive\"\r\n",
        "\r\n",
        "drive.mount(ROOT)\r\n",
        "\r\n",
        "# Check that can access the shared drive\r\n",
        "!ls \"{ROOT}/Shareddrives/CS 175 Project\""
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'AElfric to Albert User Evaluation Study.gform'\n",
            " Datasets\n",
            " Diagrams\n",
            " models\n",
            " Notebooks\n",
            "'Papers Other Resources'\n",
            "'Progress Reports'\n",
            " Proposal\n",
            "'Team AElfrictoAlbert.gsheet'\n",
            " token.txt\n",
            "'User Evaluation Study Key.gdoc'\n",
            "'Yanqi making it repo public.gdoc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTJLiqgn1X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c42e60-e1ee-4547-fa74-2decf1e785d6"
      },
      "source": [
        "# Clone github repository setup\r\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\r\n",
        "from os.path import join  \r\n",
        "\r\n",
        "# path to your project on Google Drive\r\n",
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/cs175-Aelfric-to-Albert' \r\n",
        "GIT_USERNAME = \"mayaschwarz\" \r\n",
        "\r\n",
        "# Put your Token here! Do not save to the repo with it!\r\n",
        "GIT_TOKEN_PATH = join(ROOT, \"Shareddrives/CS 175 Project/token.txt\")\r\n",
        "GIT_TOKEN = \"\"\r\n",
        "\r\n",
        "with open(GIT_TOKEN_PATH, 'r') as f:\r\n",
        "  GIT_TOKEN = f.readline().strip()\r\n",
        "\r\n",
        "if not GIT_TOKEN:\r\n",
        "  raise ValueError(\"GIT_TOKEN MISSING\")\r\n",
        "\r\n",
        "GIT_REPOSITORY = \"cs175--lfric-to-Albert\" \r\n",
        "\r\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\r\n",
        "\r\n",
        "# It's good to print out the value if you are not sure \r\n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \r\n",
        "\r\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\r\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\r\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  /content/gdrive/My Drive/cs175-Aelfric-to-Albert\n",
            "GIT_PATH:  https://5724b257c777c6dbb9bc086821f822ef220e3126@github.com/mayaschwarz/cs175--lfric-to-Albert.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MsXX3Smn2hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bd8837-1f49-45a3-850c-298419540e9a"
      },
      "source": [
        "# Answer input query for downloading git repository\r\n",
        "while True:\r\n",
        "    response = input(\"Are you sure you want to download the repo? Doing so will delete all unpush work. [y|N] \").lower().strip()\r\n",
        "    if not response or response[0] == 'n':\r\n",
        "        break\r\n",
        "    elif response[0] == \"y\":\r\n",
        "        !rm -rv \"{PROJECT_PATH}\"\r\n",
        "        !mkdir -p \"{PROJECT_PATH}\" \r\n",
        "        !git clone \"{GIT_PATH}\" \"{PROJECT_PATH}\"\r\n",
        "        break\r\n",
        "\r\n",
        "# cd into the repository\r\n",
        "%cd \"{PROJECT_PATH}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are you sure you want to download the repo? Doing so will delete all unpush work. [y|N] N\n",
            "/content/gdrive/My Drive/cs175-Aelfric-to-Albert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpBwKtztn31i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d0c5fc-8bf6-4fc7-ec13-e38f0f9ad207"
      },
      "source": [
        "# Check that repository is up to date\r\n",
        "!git pull \r\n",
        "# Check which branch you're on\r\n",
        "!git branch"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is no tracking information for the current branch.\n",
            "Please specify which branch you want to merge with.\n",
            "See git-pull(1) for details.\n",
            "\n",
            "    git pull <remote> <branch>\n",
            "\n",
            "If you wish to set tracking information for this branch you can do so with:\n",
            "\n",
            "    git branch --set-upstream-to=origin/<branch> middle-and-modern-lstm\n",
            "\n",
            "  main\u001b[m\n",
            "* \u001b[32mmiddle-and-modern-lstm\u001b[m\n",
            "  old-to-modern-lstm\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA090PA8PLeH"
      },
      "source": [
        "## Setting up the Python Environment\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myfl1PLy1wZD"
      },
      "source": [
        "# On Google Colab ONLY\r\n",
        "# Reinstall Torch to avoid incompatibility with Cuda 10.1\r\n",
        "\r\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\r\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\r\n",
        "!pip install --ignore-installed torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzseqZMtlOS_"
      },
      "source": [
        "# install the rest of the packages if needed\r\n",
        "!pip install nltk==3.5 pyyaml==5.3.1 torchvision==0.7.0 cltk contractions OpenNMT-py sacrebleu tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJPEpWrpEugD"
      },
      "source": [
        "# load notebook environment variables\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3pyyJYjoGwV"
      },
      "source": [
        "# standard library\r\n",
        "import math\r\n",
        "from os import listdir\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "# additional libraries (pip install ..)\r\n",
        "import cltk\r\n",
        "import nltk\r\n",
        "import onmt\r\n",
        "from onmt.utils.misc import set_random_seed\r\n",
        "import pyonmttok\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchtext.data import Dataset\r\n",
        "import yaml\r\n",
        "\r\n",
        "# local libraries\r\n",
        "from src.data_manager import *\r\n",
        "from src.paths import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BR9QrmzTKzU",
        "outputId": "f7ef4ccd-6b69-45c5-90ec-1d110b6481bd"
      },
      "source": [
        "# For METEOR Evaluation\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqRuGHcgpLPX"
      },
      "source": [
        "def set_deterministic(seed: int = 1234):\r\n",
        "    random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    set_random_seed(seed, torch.cuda.is_available())\r\n",
        "\r\n",
        "set_deterministic()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FJ8_RlhiU_N"
      },
      "source": [
        "## Preprocessing and Tokenization\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLmGH83poeo4"
      },
      "source": [
        "from cltk.corpus.middle_english.alphabet import normalize_middle_english\r\n",
        "from cltk.phonology.old_english.phonology import Word\r\n",
        "from typing import Union\r\n",
        "\r\n",
        "def _normalize(text: str, language_code: str):\r\n",
        "    if language_code == 'ang':\r\n",
        "        # old english\r\n",
        "        DONT_NORMALIZE = '!?.&,:;\"'\r\n",
        "        normalized_words = list()\r\n",
        "        for word in text.split():\r\n",
        "            if len(word) == 0:\r\n",
        "                continue\r\n",
        "\r\n",
        "            if word[-1] in DONT_NORMALIZE:\r\n",
        "                normalized_words.append(Word(word[:-1]).ascii_encoding() + word[-1])\r\n",
        "            else:\r\n",
        "                normalized_words.append(Word(word).ascii_encoding())\r\n",
        "\r\n",
        "        return ' '.join(normalized_words)\r\n",
        "    elif language_code == 'enm':\r\n",
        "        # middle english\r\n",
        "        return normalize_middle_english(text, to_lower=False, alpha_conv=True)\r\n",
        "    return text\r\n",
        "\r\n",
        "def tokenizer(text: str, language_code: str, **kwargs: bool) -> [str]:\r\n",
        "    tok = pyonmttok.Tokenizer(\"aggressive\", joiner_annotate=True, **kwargs)\r\n",
        "    tokens, _ = tok.tokenize(_normalize(text, language_code))\r\n",
        "    return tokens\r\n",
        "\r\n",
        "def write_tokenized_dataset(dataset: {str: [str]}, source: str, source_language_code: str, target: str, target_language_code: str, file_paths: {str, Union[str, Path], Union[str, Path]}, token_kwargs: {str: bool} = {}) -> None:\r\n",
        "    \"\"\"\r\n",
        "    Given a dataset, tokenizes and writes the contents according to it's file path\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "      dataset {{str: [str]}} -- dataset returned from create_datasets\r\n",
        "      file_paths - dictionary with key as the dataset-type (training, validation, test), item as (path to source, path to target)\r\n",
        "      token_kwargs {{str: bool}} -- kwargs for the tokenizer (case_markup, etc.)\r\n",
        "    \"\"\"\r\n",
        "    for dataset_t in file_paths.keys():\r\n",
        "        src_path, tgt_path = file_paths[dataset_t]\r\n",
        "        with open(src_path, mode='w+', encoding='utf-8') as src, open(tgt_path, mode='w+', encoding='utf-8') as tgt:\r\n",
        "            src.write('\\n'.join([\" \".join(tokenizer(l, source_language_code, **token_kwargs)) for l in dataset[dataset_t][source]]))\r\n",
        "            tgt.write('\\n'.join([\" \".join(tokenizer(l, target_language_code, **token_kwargs)) for l in dataset[dataset_t][target]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPrbGwuRQQJF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDxEfQtt20T7",
        "outputId": "94f8a28c-ea4f-4ef3-d057-16f3514372d2"
      },
      "source": [
        "# Check if GPU is active\r\n",
        "# If not, go to \"Runtime\" menu > \"Change runtime type\" > \"GPU\"\r\n",
        "\r\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f52d38a7-d665-47f6-163b-621df6d6278e)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmW12nkB21K-",
        "outputId": "053331e8-ca17-4b45-a072-fecf7bc04b83"
      },
      "source": [
        "# Make sure the GPU is visable to PyTorch\r\n",
        "import torch\r\n",
        "\r\n",
        "gpu_id = torch.cuda.current_device()\r\n",
        "print(torch.cuda.is_available())\r\n",
        "print(torch.cuda.get_device_name(gpu_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Bd9FKIg-Ml"
      },
      "source": [
        "def build_and_train(config_path):\r\n",
        "    # build and store vocab in run folder\r\n",
        "    !onmt_build_vocab -config \"{config_path}\" -n_sample -1\r\n",
        "    # begin training\r\n",
        "    !onmt_train -config \"{config_path}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUZIeeDNlJJD"
      },
      "source": [
        "# Translation and Evaluation\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/translate.html) for more info on translation parameters\r\n",
        "\r\n",
        "Evaluatation using BLEU and METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oyymh304RjX"
      },
      "source": [
        "from sacrebleu import corpus_bleu\r\n",
        "from nltk.translate.meteor_score import meteor_score\r\n",
        "\r\n",
        "def calculate_meteor_score(reference: [str], hypothesis: [str]) -> float:\r\n",
        "    score = 0.0\r\n",
        "    for r, h in zip(reference, hypothesis):\r\n",
        "        score += meteor_score(r, h)\r\n",
        "    return score / len(hypothesis)\r\n",
        "\r\n",
        "def calculate_bleu_score(reference: [[str]], hypothesis: [str]) -> float:\r\n",
        "    bleu = corpus_bleu(hypothesis, reference)\r\n",
        "    return bleu.score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwt4xA_EnMmG"
      },
      "source": [
        "def evaluate(model_paths: [str], source_path: Union[str, Path], target_path: Union[str, Path], max_length: int, beam_size: 5, token_kwargs: {str:bool}, save_folder='./predictions') -> ([([str], float, float)], [str]):\r\n",
        "    tok = pyonmttok.Tokenizer(\"aggressive\", **token_kwargs)\r\n",
        "    \r\n",
        "    # retrieve and detokenize the reference\r\n",
        "    # (this ensures that any normalization techniques used do not effect the scoring)\r\n",
        "    ref = []\r\n",
        "    with open(f\"{target_path}\", encoding='utf-8') as f:\r\n",
        "        ref = [tok.detokenize(line.rstrip('\\n').split(' ')) for line in f]\r\n",
        "  \r\n",
        "    scores = []\r\n",
        "    \r\n",
        "    for m in model_paths:\r\n",
        "        m_name = m.name[:-3] if isinstance(m, Path) else m.rsplit('(\\\\|\\/)')[-1][:-3]\r\n",
        "        file_path = f\"{save_folder}/{m_name}_pred.txt\"\r\n",
        "        # Call the translate script to generate token predictions\r\n",
        "        !onmt_translate -model \"{m}\" -src \"{source_path}\" -output \"{file_path}\" -gpu 0 -beam_size \"{beam_size}\" -max_length \"{max_length}\"\r\n",
        "        \r\n",
        "        hyp = []\r\n",
        "        with open(file_path, encoding='utf8') as f:\r\n",
        "            hyp = [tok.detokenize(line.rstrip('\\n').split(' ')) for line in f]\r\n",
        "            if hyp[-1] == '':\r\n",
        "              hyp = hyp[:-1]\r\n",
        "        # get the bleu score\r\n",
        "        bleu = calculate_bleu_score([ref], hyp)\r\n",
        "        # get the meteor score\r\n",
        "        # meteor = calculate_meteor_score(ref, hyp)\r\n",
        "        scores.append((hyp, bleu, 0.0))\r\n",
        "        print(f'{m} \\t BLEU={bleu:.4f}')\r\n",
        "\r\n",
        "    return scores, ref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHfn46hoA8bw"
      },
      "source": [
        "# Configuring the Data, Model, and Training Parameters\r\n",
        "Generate a YAML file that contains all the hyperparameters and system variables necessary to build the vocab, build, and train the model.\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/build_vocab.html) for more info on building vocab\r\n",
        "\r\n",
        "See [here](https://opennmt.net/OpenNMT-py/options/train.html) for more info about building the model and training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OT26GbF_Tj"
      },
      "source": [
        "# declare the config folder to store all the yaml files\r\n",
        "CONFIG_NAME = 'openmt-config'\r\n",
        "!mkdir -p \"{CONFIG_NAME}\"\r\n",
        "CONFIG_PATH = Path(CONFIG_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqaPzHBpCpZG"
      },
      "source": [
        "## Middle and Modern English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G-C-dD0EoHQ"
      },
      "source": [
        "### Middle to Modern\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWdU14UyBZIi"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "ENM2MOD_TRANSLATE_NAME = 'enm2mod'\r\n",
        "!mkdir -p '{ENM2MOD_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "ENM2MOD_TRANSLATE_PATH = Path(ENM2MOD_TRANSLATE_NAME)\r\n",
        "ENM2MOD_RUN_PATH = ENM2MOD_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{ENM2MOD_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables\r\n",
        "ENM2MOD_SOURCE_VER = 't_wyc'\r\n",
        "ENM2MOD_SRC_LANG_CODE = 'enm'\r\n",
        "ENM2MOD_TARGET_VER = 't_kjv'\r\n",
        "ENM2MOD_TGT_LANG_CODE = 'eng'\r\n",
        "\r\n",
        "MAX_SENTENCE_LENGTH = 60\r\n",
        "\r\n",
        "# Dataset Paths\r\n",
        "DATA_PATH = Path('data/preprocessed')\r\n",
        "!mkdir -p \"{DATA_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzd-aZpnBczZ",
        "outputId": "5bf5b444-f412-4ab3-a2e1-e652383cc1f7"
      },
      "source": [
        "# Generate splits and write to files\r\n",
        "versions = get_bible_versions_by_file_name([ENM2MOD_SOURCE_VER, ENM2MOD_TARGET_VER])\r\n",
        "\r\n",
        "datasets = create_datasets(versions, .82, \r\n",
        "                preprocess_operations = [preprocess_filter_num_words(MAX_SENTENCE_LENGTH),\r\n",
        "                                         preprocess_expand_contractions(),\r\n",
        "                                         preprocess_filter_num_sentences(),\r\n",
        "                ]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding shared verses between 2 versions...        done in 0.303 seconds\n",
            "Run preprocess operations...                       done in 0.870 seconds\n",
            "Separate test verses...                            done in 0.012 seconds\n",
            "Separate validation verses...                      done in 0.020 seconds\n",
            "Zip together verses (shuffle = True)...            done in 0.031 seconds\n",
            "\n",
            "# verses before preprocessing:  28,514\n",
            "# verses after  preprocessing:  22,398 (79%)\n",
            "\n",
            "\n",
            "# training verses:    15,513 (69%)\n",
            "# validation verses:   3,406 (15%)\n",
            "# test verses:         3,479 (16%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elj5pmCtBN7X"
      },
      "source": [
        "ENM2MOD_SRC_EXT = ENM2MOD_SOURCE_VER[2:]\r\n",
        "ENM2MOD_TGT_EXT = ENM2MOD_TARGET_VER[2:]\r\n",
        "\r\n",
        "\r\n",
        "enm2mod_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-train.{ENM2MOD_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-valid.{ENM2MOD_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{ENM2MOD_SRC_EXT}', DATA_PATH / f'bible-test.{ENM2MOD_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P708lgtVg8zJ"
      },
      "source": [
        "write_tokenized_dataset(datasets, ENM2MOD_SOURCE_VER, ENM2MOD_SRC_LANG_CODE, ENM2MOD_TARGET_VER, ENM2MOD_TGT_LANG_CODE, enm2mod_file_paths, token_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5VQ6ZPA2yV"
      },
      "source": [
        "ENM2MOD_SRC_VOCAB_PATH = ENM2MOD_RUN_PATH / 'vocab.src'\r\n",
        "ENM2MOD_TGT_VOCAB_PATH = ENM2MOD_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "enm2mod_yaml = 'enm2mod.yaml'\r\n",
        "\r\n",
        "ENM2MOD_MODEL_PATH = ENM2MOD_RUN_PATH / 'models'\r\n",
        "ENM2MOD_MODEL_PREFIX = 'enm2mod'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTEGa-fAzej"
      },
      "source": [
        "config =  f'''# {enm2mod_yaml}\r\n",
        "save_data: {ENM2MOD_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {ENM2MOD_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {ENM2MOD_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    homilies:\r\n",
        "        path_src: {enm2mod_file_paths['training'][0]}\r\n",
        "        path_tgt: {enm2mod_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {enm2mod_file_paths['validation'][0]}\r\n",
        "        path_tgt: {enm2mod_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {ENM2MOD_MODEL_PATH / ENM2MOD_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {ENM2MOD_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 256\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / enm2mod_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw90EslMG2ZP",
        "outputId": "3a3c78b3-6b6b-42d8-ca2d-52f56d66cf29"
      },
      "source": [
        "build_and_train(CONFIG_PATH / enm2mod_yaml)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-04 03:19:46,729 INFO] Counter vocab from -1 samples.\n",
            "[2021-03-04 03:19:46,729 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2021-03-04 03:19:46,736 INFO] homilies's transforms: TransformPipe()\n",
            "[2021-03-04 03:19:46,738 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:19:47,138 INFO] Counters src:13530\n",
            "[2021-03-04 03:19:47,139 INFO] Counters tgt:9853\n",
            "[2021-03-04 03:19:48,172 INFO] Parsed 2 corpora from -data.\n",
            "[2021-03-04 03:19:48,173 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2021-03-04 03:19:48,173 INFO] Loading vocab from text file...\n",
            "[2021-03-04 03:19:48,173 INFO] Loading src vocabulary from enm2mod/run/vocab.src\n",
            "[2021-03-04 03:19:48,196 INFO] Loaded src vocab has 13530 tokens.\n",
            "[2021-03-04 03:19:48,201 INFO] Loading tgt vocabulary from enm2mod/run/vocab.tgt\n",
            "[2021-03-04 03:19:48,238 INFO] Loaded tgt vocab has 9853 tokens.\n",
            "[2021-03-04 03:19:48,242 INFO] Building fields with vocab in counters...\n",
            "[2021-03-04 03:19:48,253 INFO]  * tgt vocab size: 9857.\n",
            "[2021-03-04 03:19:48,269 INFO]  * src vocab size: 13532.\n",
            "[2021-03-04 03:19:48,269 INFO]  * src vocab size = 13532\n",
            "[2021-03-04 03:19:48,269 INFO]  * tgt vocab size = 9857\n",
            "[2021-03-04 03:19:48,271 INFO] Building model...\n",
            "[2021-03-04 03:19:50,489 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(13532, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(9857, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(768, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=9857, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2021-03-04 03:19:50,489 INFO] encoder: 7142400\n",
            "[2021-03-04 03:19:50,489 INFO] decoder: 13093249\n",
            "[2021-03-04 03:19:50,489 INFO] * number of parameters: 20235649\n",
            "2021-03-04 03:19:50.649300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[2021-03-04 03:19:51,814 INFO] Starting training on GPU: [0]\n",
            "[2021-03-04 03:19:51,814 INFO] Start training loop and validate every 100 steps...\n",
            "[2021-03-04 03:19:51,814 INFO] homilies's transforms: TransformPipe()\n",
            "[2021-03-04 03:19:51,816 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:20:03,937 INFO] Step 100/100000; acc:  13.93; ppl: 249.34; xent: 5.52; lr: 0.00100; 14197/16990 tok/s;     12 sec\n",
            "[2021-03-04 03:20:03,938 INFO] valid's transforms: TransformPipe()\n",
            "[2021-03-04 03:20:03,940 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:580: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1234.)\n",
            "  self.num_layers, self.dropout, self.training, self.bidirectional)\n",
            "[2021-03-04 03:20:07,149 INFO] Validation perplexity: 120.18\n",
            "[2021-03-04 03:20:07,149 INFO] Validation accuracy: 23.9959\n",
            "[2021-03-04 03:20:07,150 INFO] Model is improving acc: -inf --> 23.9959.\n",
            "[2021-03-04 03:20:19,274 INFO] Step 200/100000; acc:  28.31; ppl: 81.75; xent: 4.40; lr: 0.00100; 11459/13670 tok/s;     27 sec\n",
            "[2021-03-04 03:20:19,276 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:20:22,405 INFO] Validation perplexity: 60.4245\n",
            "[2021-03-04 03:20:22,405 INFO] Validation accuracy: 31.3843\n",
            "[2021-03-04 03:20:22,406 INFO] Model is improving acc: 23.9959 --> 31.3843.\n",
            "[2021-03-04 03:20:25,276 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:20:34,432 INFO] Step 300/100000; acc:  32.26; ppl: 52.30; xent: 3.96; lr: 0.00100; 11441/13681 tok/s;     43 sec\n",
            "[2021-03-04 03:20:34,435 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:20:37,639 INFO] Validation perplexity: 42.2303\n",
            "[2021-03-04 03:20:37,639 INFO] Validation accuracy: 35.1296\n",
            "[2021-03-04 03:20:37,639 INFO] Model is improving acc: 31.3843 --> 35.1296.\n",
            "[2021-03-04 03:20:49,604 INFO] Step 400/100000; acc:  36.78; ppl: 36.71; xent: 3.60; lr: 0.00100; 11494/13725 tok/s;     58 sec\n",
            "[2021-03-04 03:20:49,606 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:20:52,772 INFO] Validation perplexity: 30.8368\n",
            "[2021-03-04 03:20:52,772 INFO] Validation accuracy: 39.7599\n",
            "[2021-03-04 03:20:52,773 INFO] Model is improving acc: 35.1296 --> 39.7599.\n",
            "[2021-03-04 03:21:02,707 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:21:05,008 INFO] Step 500/100000; acc:  41.27; ppl: 27.03; xent: 3.30; lr: 0.00100; 11323/13545 tok/s;     73 sec\n",
            "[2021-03-04 03:21:05,010 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:21:08,132 INFO] Validation perplexity: 23.8325\n",
            "[2021-03-04 03:21:08,132 INFO] Validation accuracy: 43.827\n",
            "[2021-03-04 03:21:08,132 INFO] Model is improving acc: 39.7599 --> 43.827.\n",
            "[2021-03-04 03:21:20,462 INFO] Step 600/100000; acc:  44.78; ppl: 21.01; xent: 3.04; lr: 0.00100; 11506/13692 tok/s;     89 sec\n",
            "[2021-03-04 03:21:20,465 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:21:23,643 INFO] Validation perplexity: 19.4431\n",
            "[2021-03-04 03:21:23,643 INFO] Validation accuracy: 47.0398\n",
            "[2021-03-04 03:21:23,644 INFO] Model is improving acc: 43.827 --> 47.0398.\n",
            "[2021-03-04 03:21:38,861 INFO] Validation perplexity: 16.4834\n",
            "[2021-03-04 03:21:38,862 INFO] Validation accuracy: 49.5069\n",
            "[2021-03-04 03:21:38,862 INFO] Model is improving acc: 47.0398 --> 49.5069.\n",
            "[2021-03-04 03:21:39,315 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:21:50,826 INFO] Step 800/100000; acc:  50.29; ppl: 14.07; xent: 2.64; lr: 0.00100; 11330/13563 tok/s;    119 sec\n",
            "[2021-03-04 03:21:50,828 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:21:53,977 INFO] Validation perplexity: 14.5112\n",
            "[2021-03-04 03:21:53,977 INFO] Validation accuracy: 51.6665\n",
            "[2021-03-04 03:21:53,977 INFO] Model is improving acc: 49.5069 --> 51.6665.\n",
            "[2021-03-04 03:22:06,108 INFO] Step 900/100000; acc:  52.27; ppl: 12.22; xent: 2.50; lr: 0.00100; 11377/13605 tok/s;    134 sec\n",
            "[2021-03-04 03:22:06,110 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:22:16,539 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:22:21,410 INFO] Step 1000/100000; acc:  54.20; ppl: 10.62; xent: 2.36; lr: 0.00100; 11436/13643 tok/s;    150 sec\n",
            "[2021-03-04 03:22:21,413 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:22:24,543 INFO] Validation perplexity: 12.1848\n",
            "[2021-03-04 03:22:24,543 INFO] Validation accuracy: 54.4292\n",
            "[2021-03-04 03:22:24,544 INFO] Model is improving acc: 53.2775 --> 54.4292.\n",
            "[2021-03-04 03:22:24,609 INFO] Saving checkpoint enm2mod/run/models/enm2mod_step_1000.pt\n",
            "[2021-03-04 03:22:41,049 INFO] Validation perplexity: 11.494\n",
            "[2021-03-04 03:22:41,049 INFO] Validation accuracy: 55.4353\n",
            "[2021-03-04 03:22:41,050 INFO] Model is improving acc: 54.4292 --> 55.4353.\n",
            "[2021-03-04 03:22:51,275 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:22:53,270 INFO] Step 1200/100000; acc:  56.80; ppl:  8.68; xent: 2.16; lr: 0.00100; 11246/13438 tok/s;    181 sec\n",
            "[2021-03-04 03:22:53,272 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:22:56,407 INFO] Validation perplexity: 10.9639\n",
            "[2021-03-04 03:22:56,407 INFO] Validation accuracy: 56.1287\n",
            "[2021-03-04 03:22:56,407 INFO] Model is improving acc: 55.4353 --> 56.1287.\n",
            "[2021-03-04 03:23:08,380 INFO] Step 1300/100000; acc:  58.40; ppl:  7.70; xent: 2.04; lr: 0.00100; 11426/13701 tok/s;    197 sec\n",
            "[2021-03-04 03:23:08,382 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:23:23,706 INFO] Step 1400/100000; acc:  59.17; ppl:  7.28; xent: 1.99; lr: 0.00100; 11729/13921 tok/s;    212 sec\n",
            "[2021-03-04 03:23:23,708 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:23:26,902 INFO] Validation perplexity: 10.3181\n",
            "[2021-03-04 03:23:26,902 INFO] Validation accuracy: 57.1403\n",
            "[2021-03-04 03:23:26,903 INFO] Model is improving acc: 56.6838 --> 57.1403.\n",
            "[2021-03-04 03:23:31,699 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:23:39,030 INFO] Step 1500/100000; acc:  60.44; ppl:  6.60; xent: 1.89; lr: 0.00100; 11321/13543 tok/s;    227 sec\n",
            "[2021-03-04 03:23:39,032 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:23:42,175 INFO] Validation perplexity: 10.0901\n",
            "[2021-03-04 03:23:42,175 INFO] Validation accuracy: 57.6085\n",
            "[2021-03-04 03:23:42,175 INFO] Model is improving acc: 57.1403 --> 57.6085.\n",
            "[2021-03-04 03:23:54,227 INFO] Step 1600/100000; acc:  61.42; ppl:  6.22; xent: 1.83; lr: 0.00100; 11404/13626 tok/s;    242 sec\n",
            "[2021-03-04 03:23:54,229 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:23:57,351 INFO] Validation perplexity: 9.93093\n",
            "[2021-03-04 03:23:57,351 INFO] Validation accuracy: 57.8897\n",
            "[2021-03-04 03:23:57,352 INFO] Model is improving acc: 57.6085 --> 57.8897.\n",
            "[2021-03-04 03:24:09,024 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:24:09,567 INFO] Step 1700/100000; acc:  62.31; ppl:  5.80; xent: 1.76; lr: 0.00100; 11323/13566 tok/s;    258 sec\n",
            "[2021-03-04 03:24:09,569 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:24:12,686 INFO] Validation perplexity: 9.81578\n",
            "[2021-03-04 03:24:12,686 INFO] Validation accuracy: 58.2088\n",
            "[2021-03-04 03:24:12,686 INFO] Model is improving acc: 57.8897 --> 58.2088.\n",
            "[2021-03-04 03:24:24,531 INFO] Step 1800/100000; acc:  63.25; ppl:  5.45; xent: 1.69; lr: 0.00100; 11560/13810 tok/s;    273 sec\n",
            "[2021-03-04 03:24:24,534 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:24:27,753 INFO] Validation perplexity: 9.75752\n",
            "[2021-03-04 03:24:27,753 INFO] Validation accuracy: 58.3462\n",
            "[2021-03-04 03:24:27,753 INFO] Model is improving acc: 58.2088 --> 58.3462.\n",
            "[2021-03-04 03:24:39,820 INFO] Step 1900/100000; acc:  63.93; ppl:  5.21; xent: 1.65; lr: 0.00100; 11506/13728 tok/s;    288 sec\n",
            "[2021-03-04 03:24:39,822 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:24:42,952 INFO] Validation perplexity: 9.71347\n",
            "[2021-03-04 03:24:42,953 INFO] Validation accuracy: 58.5261\n",
            "[2021-03-04 03:24:42,953 INFO] Model is improving acc: 58.3462 --> 58.5261.\n",
            "[2021-03-04 03:24:45,366 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:24:55,057 INFO] Step 2000/100000; acc:  64.87; ppl:  4.89; xent: 1.59; lr: 0.00100; 11384/13625 tok/s;    303 sec\n",
            "[2021-03-04 03:24:55,058 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:25:11,401 INFO] Step 2100/100000; acc:  65.58; ppl:  4.72; xent: 1.55; lr: 0.00100; 10630/12711 tok/s;    320 sec\n",
            "[2021-03-04 03:25:11,403 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:25:14,525 INFO] Validation perplexity: 9.69854\n",
            "[2021-03-04 03:25:14,525 INFO] Validation accuracy: 58.7783\n",
            "[2021-03-04 03:25:14,525 INFO] Model is improving acc: 58.7015 --> 58.7783.\n",
            "[2021-03-04 03:25:23,800 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:25:26,706 INFO] Step 2200/100000; acc:  66.23; ppl:  4.49; xent: 1.50; lr: 0.00100; 11713/13927 tok/s;    335 sec\n",
            "[2021-03-04 03:25:26,708 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:25:29,942 INFO] Validation perplexity: 9.71204\n",
            "[2021-03-04 03:25:29,942 INFO] Validation accuracy: 58.9682\n",
            "[2021-03-04 03:25:29,942 INFO] Model is improving acc: 58.7783 --> 58.9682.\n",
            "[2021-03-04 03:25:41,881 INFO] Step 2300/100000; acc:  67.03; ppl:  4.28; xent: 1.45; lr: 0.00100; 11415/13623 tok/s;    350 sec\n",
            "[2021-03-04 03:25:41,884 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:25:45,000 INFO] Validation perplexity: 9.74082\n",
            "[2021-03-04 03:25:45,000 INFO] Validation accuracy: 59.0531\n",
            "[2021-03-04 03:25:45,000 INFO] Model is improving acc: 58.9682 --> 59.0531.\n",
            "[2021-03-04 03:25:57,111 INFO] Step 2400/100000; acc:  67.54; ppl:  4.16; xent: 1.42; lr: 0.00100; 11463/13719 tok/s;    365 sec\n",
            "[2021-03-04 03:25:57,113 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:26:00,250 INFO] Validation perplexity: 9.77837\n",
            "[2021-03-04 03:26:00,250 INFO] Validation accuracy: 59.1336\n",
            "[2021-03-04 03:26:00,251 INFO] Model is improving acc: 59.0531 --> 59.1336.\n",
            "[2021-03-04 03:26:00,266 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:26:12,349 INFO] Step 2500/100000; acc:  68.37; ppl:  3.94; xent: 1.37; lr: 0.00100; 11268/13499 tok/s;    381 sec\n",
            "[2021-03-04 03:26:12,351 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:26:15,486 INFO] Validation perplexity: 9.83005\n",
            "[2021-03-04 03:26:15,486 INFO] Validation accuracy: 59.149\n",
            "[2021-03-04 03:26:15,486 INFO] Model is improving acc: 59.1336 --> 59.149.\n",
            "[2021-03-04 03:26:27,507 INFO] Step 2600/100000; acc:  68.87; ppl:  3.84; xent: 1.35; lr: 0.00100; 11540/13784 tok/s;    396 sec\n",
            "[2021-03-04 03:26:27,510 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:26:30,768 INFO] Validation perplexity: 9.89524\n",
            "[2021-03-04 03:26:30,768 INFO] Validation accuracy: 59.1065\n",
            "[2021-03-04 03:26:30,769 INFO] Decreasing patience: 9/10\n",
            "[2021-03-04 03:26:37,676 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:26:42,999 INFO] Step 2700/100000; acc:  69.44; ppl:  3.70; xent: 1.31; lr: 0.00100; 11296/13489 tok/s;    411 sec\n",
            "[2021-03-04 03:26:43,001 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:26:46,110 INFO] Validation perplexity: 9.96295\n",
            "[2021-03-04 03:26:46,110 INFO] Validation accuracy: 59.1508\n",
            "[2021-03-04 03:26:46,111 INFO] Model is improving acc: 59.149 --> 59.1508.\n",
            "[2021-03-04 03:26:58,210 INFO] Step 2800/100000; acc:  70.05; ppl:  3.58; xent: 1.28; lr: 0.00100; 11417/13662 tok/s;    426 sec\n",
            "[2021-03-04 03:26:58,212 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:27:01,338 INFO] Validation perplexity: 10.0379\n",
            "[2021-03-04 03:27:01,338 INFO] Validation accuracy: 59.1842\n",
            "[2021-03-04 03:27:01,338 INFO] Model is improving acc: 59.1508 --> 59.1842.\n",
            "[2021-03-04 03:27:13,561 INFO] Step 2900/100000; acc:  70.51; ppl:  3.49; xent: 1.25; lr: 0.00100; 11356/13593 tok/s;    442 sec\n",
            "[2021-03-04 03:27:13,563 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:27:16,753 INFO] Validation perplexity: 10.12\n",
            "[2021-03-04 03:27:16,754 INFO] Validation accuracy: 59.2186\n",
            "[2021-03-04 03:27:16,754 INFO] Model is improving acc: 59.1842 --> 59.2186.\n",
            "[2021-03-04 03:27:28,803 INFO] Step 3000/100000; acc:  71.12; ppl:  3.37; xent: 1.21; lr: 0.00100; 11642/13864 tok/s;    457 sec\n",
            "[2021-03-04 03:27:28,806 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:27:31,914 INFO] Validation perplexity: 10.2107\n",
            "[2021-03-04 03:27:31,914 INFO] Validation accuracy: 59.2077\n",
            "[2021-03-04 03:27:31,915 INFO] Decreasing patience: 9/10\n",
            "[2021-03-04 03:27:31,979 INFO] Saving checkpoint enm2mod/run/models/enm2mod_step_3000.pt\n",
            "[2021-03-04 03:27:45,229 INFO] Step 3100/100000; acc:  71.22; ppl:  3.32; xent: 1.20; lr: 0.00100; 10677/12737 tok/s;    473 sec\n",
            "[2021-03-04 03:27:45,231 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:27:48,382 INFO] Validation perplexity: 10.3059\n",
            "[2021-03-04 03:27:48,382 INFO] Validation accuracy: 59.2584\n",
            "[2021-03-04 03:27:48,382 INFO] Model is improving acc: 59.2186 --> 59.2584.\n",
            "[2021-03-04 03:27:52,618 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:28:00,590 INFO] Step 3200/100000; acc:  72.35; ppl:  3.14; xent: 1.14; lr: 0.00100; 11247/13454 tok/s;    489 sec\n",
            "[2021-03-04 03:28:00,593 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:28:03,778 INFO] Validation perplexity: 10.4029\n",
            "[2021-03-04 03:28:03,778 INFO] Validation accuracy: 59.2394\n",
            "[2021-03-04 03:28:03,779 INFO] Decreasing patience: 9/10\n",
            "[2021-03-04 03:28:15,962 INFO] Step 3300/100000; acc:  72.50; ppl:  3.11; xent: 1.13; lr: 0.00100; 11264/13472 tok/s;    504 sec\n",
            "[2021-03-04 03:28:15,965 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:28:19,184 INFO] Validation perplexity: 10.5073\n",
            "[2021-03-04 03:28:19,184 INFO] Validation accuracy: 59.2394\n",
            "[2021-03-04 03:28:19,184 INFO] Decreasing patience: 8/10\n",
            "[2021-03-04 03:28:30,338 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:28:31,315 INFO] Step 3400/100000; acc:  73.09; ppl:  3.01; xent: 1.10; lr: 0.00100; 11375/13603 tok/s;    520 sec\n",
            "[2021-03-04 03:28:31,317 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:28:34,460 INFO] Validation perplexity: 10.6204\n",
            "[2021-03-04 03:28:34,460 INFO] Validation accuracy: 59.2358\n",
            "[2021-03-04 03:28:34,460 INFO] Decreasing patience: 7/10\n",
            "[2021-03-04 03:28:46,518 INFO] Step 3500/100000; acc:  73.52; ppl:  2.94; xent: 1.08; lr: 0.00100; 11398/13624 tok/s;    535 sec\n",
            "[2021-03-04 03:28:46,521 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:28:49,630 INFO] Validation perplexity: 10.7553\n",
            "[2021-03-04 03:28:49,630 INFO] Validation accuracy: 59.2123\n",
            "[2021-03-04 03:28:49,630 INFO] Decreasing patience: 6/10\n",
            "[2021-03-04 03:29:01,763 INFO] Step 3600/100000; acc:  73.87; ppl:  2.90; xent: 1.06; lr: 0.00100; 11545/13757 tok/s;    550 sec\n",
            "[2021-03-04 03:29:01,765 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:29:04,919 INFO] Validation perplexity: 10.8688\n",
            "[2021-03-04 03:29:04,919 INFO] Validation accuracy: 59.2249\n",
            "[2021-03-04 03:29:04,920 INFO] Decreasing patience: 5/10\n",
            "[2021-03-04 03:29:06,892 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:29:16,994 INFO] Step 3700/100000; acc:  74.63; ppl:  2.78; xent: 1.02; lr: 0.00100; 11338/13592 tok/s;    565 sec\n",
            "[2021-03-04 03:29:16,996 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:29:20,211 INFO] Validation perplexity: 10.9982\n",
            "[2021-03-04 03:29:20,212 INFO] Validation accuracy: 59.1725\n",
            "[2021-03-04 03:29:20,212 INFO] Decreasing patience: 4/10\n",
            "[2021-03-04 03:29:35,596 INFO] Validation perplexity: 11.1232\n",
            "[2021-03-04 03:29:35,596 INFO] Validation accuracy: 59.1481\n",
            "[2021-03-04 03:29:35,596 INFO] Decreasing patience: 3/10\n",
            "[2021-03-04 03:29:44,360 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:29:47,732 INFO] Step 3900/100000; acc:  75.34; ppl:  2.68; xent: 0.99; lr: 0.00100; 11427/13656 tok/s;    596 sec\n",
            "[2021-03-04 03:29:47,734 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:29:50,859 INFO] Validation perplexity: 11.2492\n",
            "[2021-03-04 03:29:50,859 INFO] Validation accuracy: 59.1219\n",
            "[2021-03-04 03:29:50,859 INFO] Decreasing patience: 2/10\n",
            "[2021-03-04 03:30:02,788 INFO] Step 4000/100000; acc:  75.77; ppl:  2.62; xent: 0.96; lr: 0.00100; 11457/13686 tok/s;    611 sec\n",
            "[2021-03-04 03:30:02,790 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:30:18,739 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.wyc, data/preprocessed/bible-train.kjv, align=None)...\n",
            "[2021-03-04 03:30:19,268 INFO] Step 4100/100000; acc:  75.99; ppl:  2.59; xent: 0.95; lr: 0.00100; 10580/12646 tok/s;    627 sec\n",
            "[2021-03-04 03:30:19,270 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.wyc, data/preprocessed/bible-valid.kjv, align=None)...\n",
            "[2021-03-04 03:30:22,651 INFO] Validation perplexity: 11.531\n",
            "[2021-03-04 03:30:22,651 INFO] Validation accuracy: 59.0821\n",
            "[2021-03-04 03:30:22,651 INFO] Decreasing patience: 0/10\n",
            "[2021-03-04 03:30:22,651 INFO] Training finished after not improving. Early Stop!\n",
            "[2021-03-04 03:30:22,652 INFO] Best model found at step 3100\n",
            "[2021-03-04 03:30:22,720 INFO] Saving checkpoint enm2mod/run/models/enm2mod_step_4100.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvDyin8CBtTt",
        "outputId": "cd65208f-5ed6-4398-c360-ba80a93f64ef"
      },
      "source": [
        "# retrieve the models\r\n",
        "enm2mod_model_paths = [ ENM2MOD_MODEL_PATH / f for f in listdir(ENM2MOD_MODEL_PATH) if f.startswith(ENM2MOD_MODEL_PREFIX)]\r\n",
        "\r\n",
        "ENM2MOD_PREDICTIONS_PATH = ENM2MOD_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{ENM2MOD_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "enm2mod_scores, _ = evaluate(enm2mod_model_paths, enm2mod_file_paths['test'][0], enm2mod_file_paths['test'][1], MAX_SENTENCE_LENGTH, 10, token_kwargs, ENM2MOD_PREDICTIONS_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-04 03:30:27,494 INFO] Translating shard 0.\n",
            "[2021-03-04 03:30:54,879 INFO] PRED AVG SCORE: -0.8870, PRED PPL: 2.4279\n",
            "enm2mod/run/models/enm2mod_step_1000.pt \t BLEU=17.2577\n",
            "[2021-03-04 03:30:59,571 INFO] Translating shard 0.\n",
            "[2021-03-04 03:31:26,516 INFO] PRED AVG SCORE: -0.6079, PRED PPL: 1.8365\n",
            "enm2mod/run/models/enm2mod_step_2000.pt \t BLEU=22.7357\n",
            "[2021-03-04 03:31:31,199 INFO] Translating shard 0.\n",
            "enm2mod/run/models/enm2mod_step_3000.pt \t BLEU=23.4319\n",
            "[2021-03-04 03:32:03,042 INFO] Translating shard 0.\n",
            "[2021-03-04 03:32:30,027 INFO] PRED AVG SCORE: -0.4346, PRED PPL: 1.5443\n",
            "enm2mod/run/models/enm2mod_step_4000.pt \t BLEU=23.5675\n",
            "[2021-03-04 03:32:34,729 INFO] Translating shard 0.\n",
            "[2021-03-04 03:33:01,824 INFO] PRED AVG SCORE: -0.4309, PRED PPL: 1.5387\n",
            "enm2mod/run/models/enm2mod_step_4100.pt \t BLEU=23.3729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-80sPpwGlLvL"
      },
      "source": [
        "Using BLEU Scoring, the best performing model is after 4000 training iterations with a BLEU score of ~ 23.57\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRLR8eZFT4Go"
      },
      "source": [
        "### Modern to Middle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFbUFqBwGiC2"
      },
      "source": [
        "We can reuse the preprocessing files saved from the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qEGECBoEsqx"
      },
      "source": [
        "MOD2ENM_TRANSLATE_NAME = 'mod2enm'\r\n",
        "!mkdir -p '{MOD2ENM_TRANSLATE_NAME}'\r\n",
        "\r\n",
        "# PATH VARIABLES\r\n",
        "MOD2ENM_TRANSLATE_PATH = Path(MOD2ENM_TRANSLATE_NAME)\r\n",
        "MOD2ENM_RUN_PATH = MOD2ENM_TRANSLATE_PATH / 'run'\r\n",
        "!mkdir -p \"{MOD2ENM_RUN_PATH}\"\r\n",
        "\r\n",
        "# Dataset Variables (swap previous run)\r\n",
        "MOD2ENM_SOURCE_VER = 't_kjv'\r\n",
        "MOD2ENM_TARGET_VER = 't_wyc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPcBIfqUE9dg"
      },
      "source": [
        "MOD2ENM_SRC_EXT = MOD2ENM_SOURCE_VER[2:]\r\n",
        "MOD2ENM_TGT_EXT = MOD2ENM_TARGET_VER[2:]\r\n",
        "\r\n",
        "mod2enm_file_paths = {\r\n",
        "    'training' : (DATA_PATH / f'bible-train.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-train.{MOD2ENM_TGT_EXT}'),\r\n",
        "    'validation' : (DATA_PATH / f'bible-valid.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-valid.{MOD2ENM_TGT_EXT}'),\r\n",
        "    'test' : (DATA_PATH / f'bible-test.{MOD2ENM_SRC_EXT}', DATA_PATH / f'bible-test.{MOD2ENM_TGT_EXT}')\r\n",
        "    }\r\n",
        "\r\n",
        "token_kwargs = {\r\n",
        "    'case_markup': True\r\n",
        "    }\r\n",
        "\r\n",
        "# datasets are already tokenized by the first run, no need to do again\r\n",
        "# write_tokenized_dataset(datasets, file_paths, token_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsQxvqJMdRn8"
      },
      "source": [
        "MOD2ENM_SRC_VOCAB_PATH = MOD2ENM_RUN_PATH / 'vocab.src'\r\n",
        "MOD2ENM_TGT_VOCAB_PATH = MOD2ENM_RUN_PATH / 'vocab.tgt'\r\n",
        "\r\n",
        "mod2enm_yaml = 'mod2enm.yaml'\r\n",
        "\r\n",
        "MOD2ENM_MODEL_PATH = MOD2ENM_RUN_PATH / 'models'\r\n",
        "MOD2ENM_MODEL_PREFIX = 'mod2enm'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzJIRf0IF0A9"
      },
      "source": [
        "config =  f'''# {mod2enm_yaml}\r\n",
        "save_data: {MOD2ENM_RUN_PATH}\r\n",
        "\r\n",
        "### DATA PROPROCESSING ###\r\n",
        "## Where the vocab(s) will be written\r\n",
        "src_vocab: {MOD2ENM_SRC_VOCAB_PATH}\r\n",
        "tgt_vocab: {MOD2ENM_TGT_VOCAB_PATH}\r\n",
        "\r\n",
        "# Corpus opts:\r\n",
        "data:\r\n",
        "    homilies:\r\n",
        "        path_src: {mod2enm_file_paths['training'][0]}\r\n",
        "        path_tgt: {mod2enm_file_paths['training'][1]}\r\n",
        "        transforms: []\r\n",
        "        weight: 1\r\n",
        "    valid:\r\n",
        "        path_src: {mod2enm_file_paths['validation'][0]}\r\n",
        "        path_tgt: {mod2enm_file_paths['validation'][1]}\r\n",
        "        transforms: []\r\n",
        "\r\n",
        "## silently ignore empty lines in data\r\n",
        "skip_empty_level: silent\r\n",
        "\r\n",
        "### TRAINING ###\r\n",
        "## Where the model will be saved\r\n",
        "save_model: {MOD2ENM_MODEL_PATH / MOD2ENM_MODEL_PREFIX}\r\n",
        "save_checkpoint_steps: 1000\r\n",
        "average_decay: 0.0005\r\n",
        "seed: 1234\r\n",
        "report_every: 100\r\n",
        "train_steps: 100000\r\n",
        "valid_steps: 100\r\n",
        "early_stopping: 10\r\n",
        "early_stopping_criteria: accuracy\r\n",
        "tensorboard: True\r\n",
        "tensorboard_log_dir: {MOD2ENM_RUN_PATH / 'logs'}\r\n",
        "\r\n",
        "# Batching\r\n",
        "world_size: 1\r\n",
        "gpu_ranks: [0]\r\n",
        "batch_size: 64\r\n",
        "valid_batch_size: 64\r\n",
        "batch_size_multiple: 1\r\n",
        "\r\n",
        "# Optimization\r\n",
        "model_dtype: \"fp32\"\r\n",
        "optim: \"adam\"\r\n",
        "learning_rate: 0.001\r\n",
        "\r\n",
        "# Model\r\n",
        "encoder_type: rnn\r\n",
        "decoder_type: rnn\r\n",
        "rnn_type: LSTM\r\n",
        "enc_layers: 2\r\n",
        "dec_layers: 2\r\n",
        "rnn_size: 512\r\n",
        "word_vec_size: 256\r\n",
        "'''\r\n",
        "\r\n",
        "with open(CONFIG_PATH / mod2enm_yaml, \"w+\") as config_yaml:\r\n",
        "  config_yaml.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yfSnvqCG5ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f3f8b4-3272-41be-d228-12534425ee58"
      },
      "source": [
        "build_and_train(CONFIG_PATH / mod2enm_yaml)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-04 03:33:04,455 INFO] Counter vocab from -1 samples.\n",
            "[2021-03-04 03:33:04,455 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2021-03-04 03:33:04,462 INFO] homilies's transforms: TransformPipe()\n",
            "[2021-03-04 03:33:04,463 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:33:04,864 INFO] Counters src:9853\n",
            "[2021-03-04 03:33:04,864 INFO] Counters tgt:13530\n",
            "[2021-03-04 03:33:05,862 INFO] Parsed 2 corpora from -data.\n",
            "[2021-03-04 03:33:05,863 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2021-03-04 03:33:05,863 INFO] Loading vocab from text file...\n",
            "[2021-03-04 03:33:05,863 INFO] Loading src vocabulary from mod2enm/run/vocab.src\n",
            "[2021-03-04 03:33:05,880 INFO] Loaded src vocab has 9853 tokens.\n",
            "[2021-03-04 03:33:05,883 INFO] Loading tgt vocabulary from mod2enm/run/vocab.tgt\n",
            "[2021-03-04 03:33:05,925 INFO] Loaded tgt vocab has 13530 tokens.\n",
            "[2021-03-04 03:33:05,931 INFO] Building fields with vocab in counters...\n",
            "[2021-03-04 03:33:05,948 INFO]  * tgt vocab size: 13534.\n",
            "[2021-03-04 03:33:05,958 INFO]  * src vocab size: 9855.\n",
            "[2021-03-04 03:33:05,959 INFO]  * src vocab size = 9855\n",
            "[2021-03-04 03:33:05,959 INFO]  * tgt vocab size = 13534\n",
            "[2021-03-04 03:33:05,960 INFO] Building model...\n",
            "[2021-03-04 03:33:08,183 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(9855, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(13534, 256, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(768, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=13534, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2021-03-04 03:33:08,183 INFO] encoder: 6201088\n",
            "[2021-03-04 03:33:08,183 INFO] decoder: 15920862\n",
            "[2021-03-04 03:33:08,183 INFO] * number of parameters: 22121950\n",
            "2021-03-04 03:33:08.344265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[2021-03-04 03:33:09,515 INFO] Starting training on GPU: [0]\n",
            "[2021-03-04 03:33:09,515 INFO] Start training loop and validate every 100 steps...\n",
            "[2021-03-04 03:33:09,515 INFO] homilies's transforms: TransformPipe()\n",
            "[2021-03-04 03:33:09,517 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:33:20,648 INFO] Step 100/100000; acc:  11.40; ppl: 349.41; xent: 5.86; lr: 0.00100; 17917/16031 tok/s;     11 sec\n",
            "[2021-03-04 03:33:20,649 INFO] valid's transforms: TransformPipe()\n",
            "[2021-03-04 03:33:20,650 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:580: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1234.)\n",
            "  self.num_layers, self.dropout, self.training, self.bidirectional)\n",
            "[2021-03-04 03:33:23,639 INFO] Validation perplexity: 194.878\n",
            "[2021-03-04 03:33:23,639 INFO] Validation accuracy: 19.3635\n",
            "[2021-03-04 03:33:23,639 INFO] Model is improving acc: -inf --> 19.3635.\n",
            "[2021-03-04 03:33:37,640 INFO] Validation perplexity: 98.5327\n",
            "[2021-03-04 03:33:37,641 INFO] Validation accuracy: 25.5537\n",
            "[2021-03-04 03:33:37,641 INFO] Model is improving acc: 19.3635 --> 25.5537.\n",
            "[2021-03-04 03:33:40,366 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:33:48,558 INFO] Step 300/100000; acc:  26.72; ppl: 84.44; xent: 4.44; lr: 0.00100; 14494/12967 tok/s;     39 sec\n",
            "[2021-03-04 03:33:48,560 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:33:51,588 INFO] Validation perplexity: 68.6238\n",
            "[2021-03-04 03:33:51,589 INFO] Validation accuracy: 29.9613\n",
            "[2021-03-04 03:33:51,589 INFO] Model is improving acc: 25.5537 --> 29.9613.\n",
            "[2021-03-04 03:34:02,732 INFO] Step 400/100000; acc:  32.08; ppl: 57.23; xent: 4.05; lr: 0.00100; 14252/12751 tok/s;     53 sec\n",
            "[2021-03-04 03:34:02,735 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:34:05,698 INFO] Validation perplexity: 48.2297\n",
            "[2021-03-04 03:34:05,698 INFO] Validation accuracy: 35.3598\n",
            "[2021-03-04 03:34:05,699 INFO] Model is improving acc: 29.9613 --> 35.3598.\n",
            "[2021-03-04 03:34:14,891 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:34:16,937 INFO] Step 500/100000; acc:  36.89; ppl: 41.38; xent: 3.72; lr: 0.00100; 14221/12739 tok/s;     67 sec\n",
            "[2021-03-04 03:34:16,940 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:34:19,898 INFO] Validation perplexity: 36.2558\n",
            "[2021-03-04 03:34:19,898 INFO] Validation accuracy: 40.0099\n",
            "[2021-03-04 03:34:19,899 INFO] Model is improving acc: 35.3598 --> 40.0099.\n",
            "[2021-03-04 03:34:31,281 INFO] Step 600/100000; acc:  41.29; ppl: 30.45; xent: 3.42; lr: 0.00100; 14329/12820 tok/s;     82 sec\n",
            "[2021-03-04 03:34:31,283 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:34:34,246 INFO] Validation perplexity: 29.0851\n",
            "[2021-03-04 03:34:34,246 INFO] Validation accuracy: 43.3553\n",
            "[2021-03-04 03:34:34,246 INFO] Model is improving acc: 40.0099 --> 43.3553.\n",
            "[2021-03-04 03:34:45,278 INFO] Step 700/100000; acc:  44.25; ppl: 24.54; xent: 3.20; lr: 0.00100; 14495/12987 tok/s;     96 sec\n",
            "[2021-03-04 03:34:45,280 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:34:48,339 INFO] Validation perplexity: 24.4983\n",
            "[2021-03-04 03:34:48,339 INFO] Validation accuracy: 45.9214\n",
            "[2021-03-04 03:34:48,339 INFO] Model is improving acc: 43.3553 --> 45.9214.\n",
            "[2021-03-04 03:34:48,714 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:35:02,064 INFO] Validation perplexity: 21.4871\n",
            "[2021-03-04 03:35:02,065 INFO] Validation accuracy: 48.0563\n",
            "[2021-03-04 03:35:02,065 INFO] Model is improving acc: 45.9214 --> 48.0563.\n",
            "[2021-03-04 03:35:13,348 INFO] Step 900/100000; acc:  48.76; ppl: 17.06; xent: 2.84; lr: 0.00100; 14157/12680 tok/s;    124 sec\n",
            "[2021-03-04 03:35:13,350 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:35:16,300 INFO] Validation perplexity: 19.3676\n",
            "[2021-03-04 03:35:16,300 INFO] Validation accuracy: 49.6347\n",
            "[2021-03-04 03:35:16,301 INFO] Model is improving acc: 48.0563 --> 49.6347.\n",
            "[2021-03-04 03:35:22,968 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:35:30,317 INFO] Validation perplexity: 17.7918\n",
            "[2021-03-04 03:35:30,317 INFO] Validation accuracy: 51.0327\n",
            "[2021-03-04 03:35:30,317 INFO] Model is improving acc: 49.6347 --> 51.0327.\n",
            "[2021-03-04 03:35:30,382 INFO] Saving checkpoint mod2enm/run/models/mod2enm_step_1000.pt\n",
            "[2021-03-04 03:35:42,565 INFO] Step 1100/100000; acc:  52.74; ppl: 12.56; xent: 2.53; lr: 0.00100; 13192/11825 tok/s;    153 sec\n",
            "[2021-03-04 03:35:42,568 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:35:45,788 INFO] Validation perplexity: 16.683\n",
            "[2021-03-04 03:35:45,788 INFO] Validation accuracy: 52.0691\n",
            "[2021-03-04 03:35:45,789 INFO] Model is improving acc: 51.0327 --> 52.0691.\n",
            "[2021-03-04 03:35:55,219 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:35:56,933 INFO] Step 1200/100000; acc:  53.78; ppl: 11.37; xent: 2.43; lr: 0.00100; 14140/12657 tok/s;    167 sec\n",
            "[2021-03-04 03:35:56,935 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:36:10,865 INFO] Step 1300/100000; acc:  55.51; ppl:  9.94; xent: 2.30; lr: 0.00100; 14375/12863 tok/s;    181 sec\n",
            "[2021-03-04 03:36:10,867 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:36:13,808 INFO] Validation perplexity: 15.2655\n",
            "[2021-03-04 03:36:13,809 INFO] Validation accuracy: 53.5003\n",
            "[2021-03-04 03:36:13,809 INFO] Model is improving acc: 52.8505 --> 53.5003.\n",
            "[2021-03-04 03:36:25,100 INFO] Step 1400/100000; acc:  56.40; ppl:  9.27; xent: 2.23; lr: 0.00100; 14587/13042 tok/s;    196 sec\n",
            "[2021-03-04 03:36:25,102 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:36:28,120 INFO] Validation perplexity: 14.8164\n",
            "[2021-03-04 03:36:28,120 INFO] Validation accuracy: 54.1387\n",
            "[2021-03-04 03:36:28,121 INFO] Model is improving acc: 53.5003 --> 54.1387.\n",
            "[2021-03-04 03:36:32,500 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:36:39,057 INFO] Step 1500/100000; acc:  57.68; ppl:  8.33; xent: 2.12; lr: 0.00100; 14404/12897 tok/s;    210 sec\n",
            "[2021-03-04 03:36:39,059 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:36:42,035 INFO] Validation perplexity: 14.4439\n",
            "[2021-03-04 03:36:42,036 INFO] Validation accuracy: 54.5056\n",
            "[2021-03-04 03:36:42,036 INFO] Model is improving acc: 54.1387 --> 54.5056.\n",
            "[2021-03-04 03:36:53,325 INFO] Step 1600/100000; acc:  58.95; ppl:  7.67; xent: 2.04; lr: 0.00100; 14058/12599 tok/s;    224 sec\n",
            "[2021-03-04 03:36:53,327 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:36:56,315 INFO] Validation perplexity: 14.2267\n",
            "[2021-03-04 03:36:56,315 INFO] Validation accuracy: 54.9761\n",
            "[2021-03-04 03:36:56,315 INFO] Model is improving acc: 54.5056 --> 54.9761.\n",
            "[2021-03-04 03:37:07,589 INFO] Step 1700/100000; acc:  59.67; ppl:  7.17; xent: 1.97; lr: 0.00100; 14119/12639 tok/s;    238 sec\n",
            "[2021-03-04 03:37:07,592 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:37:10,590 INFO] Validation perplexity: 14.0379\n",
            "[2021-03-04 03:37:10,590 INFO] Validation accuracy: 55.229\n",
            "[2021-03-04 03:37:10,590 INFO] Model is improving acc: 54.9761 --> 55.229.\n",
            "[2021-03-04 03:37:21,628 INFO] Step 1800/100000; acc:  61.08; ppl:  6.53; xent: 1.88; lr: 0.00100; 14278/12766 tok/s;    252 sec\n",
            "[2021-03-04 03:37:21,630 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:37:24,708 INFO] Validation perplexity: 13.9549\n",
            "[2021-03-04 03:37:24,708 INFO] Validation accuracy: 55.5368\n",
            "[2021-03-04 03:37:24,708 INFO] Model is improving acc: 55.229 --> 55.5368.\n",
            "[2021-03-04 03:37:35,732 INFO] Step 1900/100000; acc:  61.77; ppl:  6.25; xent: 1.83; lr: 0.00100; 14428/12944 tok/s;    266 sec\n",
            "[2021-03-04 03:37:35,735 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:37:38,678 INFO] Validation perplexity: 13.9177\n",
            "[2021-03-04 03:37:38,678 INFO] Validation accuracy: 55.7793\n",
            "[2021-03-04 03:37:38,679 INFO] Model is improving acc: 55.5368 --> 55.7793.\n",
            "[2021-03-04 03:37:40,969 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:37:49,610 INFO] Step 2000/100000; acc:  62.90; ppl:  5.77; xent: 1.75; lr: 0.00100; 14484/12941 tok/s;    280 sec\n",
            "[2021-03-04 03:37:49,612 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:37:52,571 INFO] Validation perplexity: 13.8682\n",
            "[2021-03-04 03:37:52,571 INFO] Validation accuracy: 55.9555\n",
            "[2021-03-04 03:37:52,571 INFO] Model is improving acc: 55.7793 --> 55.9555.\n",
            "[2021-03-04 03:37:52,636 INFO] Saving checkpoint mod2enm/run/models/mod2enm_step_2000.pt\n",
            "[2021-03-04 03:38:05,093 INFO] Step 2100/100000; acc:  63.74; ppl:  5.51; xent: 1.71; lr: 0.00100; 13006/11648 tok/s;    296 sec\n",
            "[2021-03-04 03:38:05,095 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:38:08,053 INFO] Validation perplexity: 13.9057\n",
            "[2021-03-04 03:38:08,053 INFO] Validation accuracy: 56.1514\n",
            "[2021-03-04 03:38:08,053 INFO] Model is improving acc: 55.9555 --> 56.1514.\n",
            "[2021-03-04 03:38:16,734 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:38:19,401 INFO] Step 2200/100000; acc:  64.06; ppl:  5.27; xent: 1.66; lr: 0.00100; 14489/12944 tok/s;    310 sec\n",
            "[2021-03-04 03:38:19,403 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:38:22,494 INFO] Validation perplexity: 13.9511\n",
            "[2021-03-04 03:38:22,494 INFO] Validation accuracy: 56.2239\n",
            "[2021-03-04 03:38:22,494 INFO] Model is improving acc: 56.1514 --> 56.2239.\n",
            "[2021-03-04 03:38:33,632 INFO] Step 2300/100000; acc:  65.49; ppl:  4.89; xent: 1.59; lr: 0.00100; 14078/12633 tok/s;    324 sec\n",
            "[2021-03-04 03:38:33,634 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:38:36,579 INFO] Validation perplexity: 14.0212\n",
            "[2021-03-04 03:38:36,579 INFO] Validation accuracy: 56.3586\n",
            "[2021-03-04 03:38:36,580 INFO] Model is improving acc: 56.2239 --> 56.3586.\n",
            "[2021-03-04 03:38:47,613 INFO] Step 2400/100000; acc:  65.93; ppl:  4.74; xent: 1.56; lr: 0.00100; 14465/12951 tok/s;    338 sec\n",
            "[2021-03-04 03:38:47,615 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:38:50,574 INFO] Validation perplexity: 14.1248\n",
            "[2021-03-04 03:38:50,574 INFO] Validation accuracy: 56.4011\n",
            "[2021-03-04 03:38:50,575 INFO] Model is improving acc: 56.3586 --> 56.4011.\n",
            "[2021-03-04 03:38:50,591 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:39:04,583 INFO] Validation perplexity: 14.2356\n",
            "[2021-03-04 03:39:04,583 INFO] Validation accuracy: 56.5203\n",
            "[2021-03-04 03:39:04,583 INFO] Model is improving acc: 56.4011 --> 56.5203.\n",
            "[2021-03-04 03:39:15,614 INFO] Step 2600/100000; acc:  67.53; ppl:  4.35; xent: 1.47; lr: 0.00100; 14490/12974 tok/s;    366 sec\n",
            "[2021-03-04 03:39:15,616 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:39:18,662 INFO] Validation perplexity: 14.3588\n",
            "[2021-03-04 03:39:18,662 INFO] Validation accuracy: 56.5379\n",
            "[2021-03-04 03:39:18,662 INFO] Model is improving acc: 56.5203 --> 56.5379.\n",
            "[2021-03-04 03:39:24,942 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:39:32,602 INFO] Validation perplexity: 14.4801\n",
            "[2021-03-04 03:39:32,602 INFO] Validation accuracy: 56.6239\n",
            "[2021-03-04 03:39:32,603 INFO] Model is improving acc: 56.5379 --> 56.6239.\n",
            "[2021-03-04 03:39:43,762 INFO] Step 2800/100000; acc:  68.93; ppl:  3.96; xent: 1.38; lr: 0.00100; 14256/12785 tok/s;    394 sec\n",
            "[2021-03-04 03:39:43,763 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:39:46,758 INFO] Validation perplexity: 14.6549\n",
            "[2021-03-04 03:39:46,758 INFO] Validation accuracy: 56.6146\n",
            "[2021-03-04 03:39:46,759 INFO] Decreasing patience: 9/10\n",
            "[2021-03-04 03:39:55,741 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:39:57,830 INFO] Step 2900/100000; acc:  69.01; ppl:  3.91; xent: 1.36; lr: 0.00100; 14368/12839 tok/s;    408 sec\n",
            "[2021-03-04 03:39:57,832 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:40:00,868 INFO] Validation perplexity: 14.8068\n",
            "[2021-03-04 03:40:00,868 INFO] Validation accuracy: 56.6447\n",
            "[2021-03-04 03:40:00,869 INFO] Model is improving acc: 56.6239 --> 56.6447.\n",
            "[2021-03-04 03:40:14,931 INFO] Validation perplexity: 14.9515\n",
            "[2021-03-04 03:40:14,931 INFO] Validation accuracy: 56.6447\n",
            "[2021-03-04 03:40:14,932 INFO] Stalled patience: 9/10\n",
            "[2021-03-04 03:40:14,997 INFO] Saving checkpoint mod2enm/run/models/mod2enm_step_3000.pt\n",
            "[2021-03-04 03:40:27,169 INFO] Step 3100/100000; acc:  70.52; ppl:  3.63; xent: 1.29; lr: 0.00100; 13373/11989 tok/s;    438 sec\n",
            "[2021-03-04 03:40:27,171 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:40:30,305 INFO] Validation perplexity: 15.1325\n",
            "[2021-03-04 03:40:30,305 INFO] Validation accuracy: 56.6809\n",
            "[2021-03-04 03:40:30,306 INFO] Model is improving acc: 56.6447 --> 56.6809.\n",
            "[2021-03-04 03:40:34,332 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:40:41,391 INFO] Step 3200/100000; acc:  71.10; ppl:  3.48; xent: 1.25; lr: 0.00100; 14076/12616 tok/s;    452 sec\n",
            "[2021-03-04 03:40:41,393 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:40:55,480 INFO] Step 3300/100000; acc:  71.79; ppl:  3.38; xent: 1.22; lr: 0.00100; 14226/12752 tok/s;    466 sec\n",
            "[2021-03-04 03:40:55,482 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:40:58,520 INFO] Validation perplexity: 15.4914\n",
            "[2021-03-04 03:40:58,520 INFO] Validation accuracy: 56.7068\n",
            "[2021-03-04 03:40:58,520 INFO] Model is improving acc: 56.7058 --> 56.7068.\n",
            "[2021-03-04 03:41:08,778 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:41:09,604 INFO] Step 3400/100000; acc:  71.99; ppl:  3.31; xent: 1.20; lr: 0.00100; 14329/12826 tok/s;    480 sec\n",
            "[2021-03-04 03:41:09,606 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:41:12,559 INFO] Validation perplexity: 15.6818\n",
            "[2021-03-04 03:41:12,559 INFO] Validation accuracy: 56.6612\n",
            "[2021-03-04 03:41:12,559 INFO] Decreasing patience: 9/10\n",
            "[2021-03-04 03:41:26,644 INFO] Validation perplexity: 15.9088\n",
            "[2021-03-04 03:41:26,644 INFO] Validation accuracy: 56.6063\n",
            "[2021-03-04 03:41:26,644 INFO] Decreasing patience: 8/10\n",
            "[2021-03-04 03:41:37,759 INFO] Step 3600/100000; acc:  73.11; ppl:  3.15; xent: 1.15; lr: 0.00100; 14472/12978 tok/s;    508 sec\n",
            "[2021-03-04 03:41:37,761 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:41:40,734 INFO] Validation perplexity: 16.0926\n",
            "[2021-03-04 03:41:40,734 INFO] Validation accuracy: 56.6177\n",
            "[2021-03-04 03:41:40,734 INFO] Decreasing patience: 7/10\n",
            "[2021-03-04 03:41:42,605 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:41:51,518 INFO] Step 3700/100000; acc:  73.72; ppl:  3.01; xent: 1.10; lr: 0.00100; 14561/13001 tok/s;    522 sec\n",
            "[2021-03-04 03:41:51,520 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:41:54,587 INFO] Validation perplexity: 16.3004\n",
            "[2021-03-04 03:41:54,587 INFO] Validation accuracy: 56.5918\n",
            "[2021-03-04 03:41:54,587 INFO] Decreasing patience: 6/10\n",
            "[2021-03-04 03:42:06,101 INFO] Step 3800/100000; acc:  73.73; ppl:  3.04; xent: 1.11; lr: 0.00100; 14175/12677 tok/s;    537 sec\n",
            "[2021-03-04 03:42:06,104 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:42:09,112 INFO] Validation perplexity: 16.5427\n",
            "[2021-03-04 03:42:09,112 INFO] Validation accuracy: 56.5783\n",
            "[2021-03-04 03:42:09,113 INFO] Decreasing patience: 5/10\n",
            "[2021-03-04 03:42:17,198 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:42:20,300 INFO] Step 3900/100000; acc:  74.50; ppl:  2.90; xent: 1.06; lr: 0.00100; 14247/12759 tok/s;    551 sec\n",
            "[2021-03-04 03:42:20,303 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:42:34,373 INFO] Step 4000/100000; acc:  75.11; ppl:  2.80; xent: 1.03; lr: 0.00100; 14178/12726 tok/s;    565 sec\n",
            "[2021-03-04 03:42:34,375 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:42:37,418 INFO] Validation perplexity: 17.0209\n",
            "[2021-03-04 03:42:37,418 INFO] Validation accuracy: 56.5773\n",
            "[2021-03-04 03:42:37,418 INFO] Decreasing patience: 3/10\n",
            "[2021-03-04 03:42:37,483 INFO] Saving checkpoint mod2enm/run/models/mod2enm_step_4000.pt\n",
            "[2021-03-04 03:42:49,139 INFO] Loading ParallelCorpus(data/preprocessed/bible-train.kjv, data/preprocessed/bible-train.wyc, align=None)...\n",
            "[2021-03-04 03:42:49,572 INFO] Step 4100/100000; acc:  75.31; ppl:  2.78; xent: 1.02; lr: 0.00100; 13292/11895 tok/s;    580 sec\n",
            "[2021-03-04 03:42:49,574 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:42:52,654 INFO] Validation perplexity: 17.2688\n",
            "[2021-03-04 03:42:52,654 INFO] Validation accuracy: 56.5721\n",
            "[2021-03-04 03:42:52,654 INFO] Decreasing patience: 2/10\n",
            "[2021-03-04 03:43:06,411 INFO] Validation perplexity: 17.5419\n",
            "[2021-03-04 03:43:06,411 INFO] Validation accuracy: 56.4871\n",
            "[2021-03-04 03:43:06,412 INFO] Decreasing patience: 1/10\n",
            "[2021-03-04 03:43:17,692 INFO] Step 4300/100000; acc:  75.98; ppl:  2.69; xent: 0.99; lr: 0.00100; 14256/12787 tok/s;    608 sec\n",
            "[2021-03-04 03:43:17,694 INFO] Loading ParallelCorpus(data/preprocessed/bible-valid.kjv, data/preprocessed/bible-valid.wyc, align=None)...\n",
            "[2021-03-04 03:43:20,654 INFO] Validation perplexity: 17.8391\n",
            "[2021-03-04 03:43:20,654 INFO] Validation accuracy: 56.4633\n",
            "[2021-03-04 03:43:20,655 INFO] Decreasing patience: 0/10\n",
            "[2021-03-04 03:43:20,655 INFO] Training finished after not improving. Early Stop!\n",
            "[2021-03-04 03:43:20,655 INFO] Best model found at step 3300\n",
            "[2021-03-04 03:43:20,721 INFO] Saving checkpoint mod2enm/run/models/mod2enm_step_4300.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR9OVz2kASQU",
        "outputId": "54feceda-39cf-4266-ee04-b961a3766904"
      },
      "source": [
        "# retrieve the models\r\n",
        "mod2enm_model_paths = [ MOD2ENM_MODEL_PATH / f for f in listdir(MOD2ENM_MODEL_PATH) if f.startswith(MOD2ENM_MODEL_PREFIX)]\r\n",
        "\r\n",
        "MOD2ENM_PREDICTIONS_PATH = MOD2ENM_RUN_PATH / 'predictions'\r\n",
        "!mkdir -p \"{MOD2ENM_PREDICTIONS_PATH}\"\r\n",
        "\r\n",
        "mod2enm_scores, _ = evaluate(mod2enm_model_paths, mod2enm_file_paths['test'][0], mod2enm_file_paths['test'][1], MAX_SENTENCE_LENGTH, 10, token_kwargs, MOD2ENM_PREDICTIONS_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-04 03:43:25,540 INFO] Translating shard 0.\n",
            "mod2enm/run/models/mod2enm_step_1000.pt \t BLEU=16.3994\n",
            "[2021-03-04 03:44:00,074 INFO] Translating shard 0.\n",
            "[2021-03-04 03:44:29,053 INFO] PRED AVG SCORE: -0.6420, PRED PPL: 1.9002\n",
            "mod2enm/run/models/mod2enm_step_2000.pt \t BLEU=22.4017\n",
            "[2021-03-04 03:44:33,608 INFO] Translating shard 0.\n",
            "[2021-03-04 03:45:02,632 INFO] PRED AVG SCORE: -0.5147, PRED PPL: 1.6732\n",
            "mod2enm/run/models/mod2enm_step_3000.pt \t BLEU=23.1465\n",
            "[2021-03-04 03:45:07,155 INFO] Translating shard 0.\n",
            "[2021-03-04 03:45:35,704 INFO] PRED AVG SCORE: -0.4507, PRED PPL: 1.5694\n",
            "mod2enm/run/models/mod2enm_step_4000.pt \t BLEU=22.6068\n",
            "[2021-03-04 03:45:40,324 INFO] Translating shard 0.\n",
            "[2021-03-04 03:46:08,694 INFO] PRED AVG SCORE: -0.4365, PRED PPL: 1.5473\n",
            "mod2enm/run/models/mod2enm_step_4300.pt \t BLEU=22.4027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE0IJbgH3VC7"
      },
      "source": [
        "looking at the BLEU scores, our best model is achieved after 3000 epochs with a BLEU score of ~ 23.15"
      ]
    }
  ]
}